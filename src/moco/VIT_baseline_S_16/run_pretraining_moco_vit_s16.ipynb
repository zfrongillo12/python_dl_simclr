{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afc95ce7",
      "metadata": {
        "id": "afc95ce7"
      },
      "source": [
        "# Project Baseline Setup:\n",
        "\n",
        "### Architecture\n",
        "Run pre-training with contrastive learning (MoCo framework)\n",
        "* Use backbone - `ViT-S/16`\n",
        "* **Perform SSL Pre-training** of backbone using contrastive learning (MoCo) -> augment medical imaging dataset (Chest XRs) (Pre-text task); create positive and negative pairs\n",
        "  * Produce: `moco_vits16_encoder.pth`\n",
        "* **Transfer Learning:** Fine-tune pre-trained ResNet for Pneumonia Chest XR classification\n",
        "  * Produce: `finetuned_vits16_medical.pth`\n",
        "\n",
        "### Pre-training Dataset: CheXpert\n",
        "* Subset: Pneumonia classification only; smaller dataset (to accomodate class imbalance)\n",
        "\n",
        "### Fine-tuning Dataset: NIH Pneumonia Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c9d8de",
      "metadata": {
        "id": "f2c9d8de"
      },
      "source": [
        "###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6280d41c",
      "metadata": {
        "id": "6280d41c"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import math\n",
        "from copy import deepcopy\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "622aaf97",
      "metadata": {
        "id": "622aaf97"
      },
      "source": [
        "### Collab Needs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e4617544",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4617544",
        "outputId": "a6ff7180-0209-41d9-9930-0504112cbfd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "926e8640",
      "metadata": {
        "id": "926e8640"
      },
      "source": [
        "Define filepaths to required input (scripts, data) and outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ab89953e",
      "metadata": {
        "id": "ab89953e"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------\n",
        "# Inputs root\n",
        "# ----------------------------------------------------\n",
        "FP_ROOT=\"/content/drive/MyDrive/ViT_MoCo_Project/\"\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Dataset info\n",
        "# ----------------------------------------------------\n",
        "# Chexpert\n",
        "DATASET_PATH_SPLIT = FP_ROOT + \"Data/CheXpert_reduced_dataset_split_v3.zip\"\n",
        "\n",
        "# ChexPert\n",
        "TRAIN_LABELS_CSV = FP_ROOT + \"Data/1_final_project_updated_names_train_moco.csv\"\n",
        "TEST_LABELS_CSV = FP_ROOT + \"Data/1_final_project_updated_names_test_moco.csv\"\n",
        "\n",
        "LINEAR_TRAIN_LABELS_CSV = FP_ROOT + \"Data/2_final_project_updated_names_train_linear.csv\"\n",
        "LINEAR_TEST_LABELS_CSV = FP_ROOT + \"Data/2_final_project_updated_names_test_linear.csv\"\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Model SRC\n",
        "# ----------------------------------------------------\n",
        "SRC_ROOT = FP_ROOT + \"src/\"\n",
        "TRAIN_SCRIPT = f\"{SRC_ROOT}/train_moco_unified.py\"\n",
        "MOCO_FOLDER = f\"{SRC_ROOT}/moco\"\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Outputs\n",
        "# ----------------------------------------------------\n",
        "ROOT_ARTIFACT_SAVE = FP_ROOT + \"artifacts/vit_baseline/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "471f7e0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "471f7e0c",
        "outputId": "1e38f93c-204f-4adc-c5a8-1d1ce89256fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added /content/drive/MyDrive/ViT_MoCo_Project/src/ to sys.path\n"
          ]
        }
      ],
      "source": [
        "# Add the project /src to the system path\n",
        "if SRC_ROOT not in sys.path:\n",
        "    sys.path.append(SRC_ROOT)\n",
        "    print(f\"Added {SRC_ROOT} to sys.path\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "J_hFsGR2YOCT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_hFsGR2YOCT",
        "outputId": "4794e32c-cef5-4357-8c30-4df960b95db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmph85ibkmc', '/content/drive/MyDrive/ViT_MoCo_Project/src/']\n"
          ]
        }
      ],
      "source": [
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5459570",
      "metadata": {
        "id": "e5459570"
      },
      "source": [
        "## Unzip data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4xkMx9Qx3WuO",
      "metadata": {
        "id": "4xkMx9Qx3WuO"
      },
      "source": [
        "ChexPert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6bf584dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6bf584dd",
        "outputId": "b7c9251b-8bb5-4179-b435-3385cc929720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Dataset extracted to: /tmp/CheXpert_dataset/\n"
          ]
        }
      ],
      "source": [
        "# Unzip the dataset (image) files to /tmp\n",
        "DATA_DEST_UNZIPPED = \"/tmp/CheXpert_dataset/\"\n",
        "os.makedirs(DATA_DEST_UNZIPPED, exist_ok=True)\n",
        "print(\"Extracting dataset...\")\n",
        "!unzip -q \"{DATASET_PATH_SPLIT}\" -d {DATA_DEST_UNZIPPED}\n",
        "print(\"Dataset extracted to:\", DATA_DEST_UNZIPPED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bnjNlDPYXkRr",
      "metadata": {
        "id": "bnjNlDPYXkRr"
      },
      "outputs": [],
      "source": [
        "# Update for the unzipped sub-name\n",
        "DATA_DEST_UNZIPPED = \"/tmp/CheXpert_dataset/CheXpert_reduced_dataset_split_v3/\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1ebf977",
      "metadata": {
        "id": "a1ebf977"
      },
      "source": [
        "## 1) Run Pre-training - Contrastive Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "26858f1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26858f1d",
        "outputId": "44d16832-859b-4a88-da91-99bcba9c32c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ViT_MoCo_Project/src\n"
          ]
        }
      ],
      "source": [
        "# Run from the src directory\n",
        "%cd \"/content/drive/MyDrive/ViT_MoCo_Project/src\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTHONPATH\"] = \"/content/drive/MyDrive/ViT_MoCo_Project/src\""
      ],
      "metadata": {
        "id": "A7twJijZxdDN"
      },
      "id": "A7twJijZxdDN",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python moco/train_moco_unified.py \\\n",
        "    --precision fp16 \\\n",
        "    --train_csv_path \"$TRAIN_LABELS_CSV\" \\\n",
        "    --root_dir \"$DATA_DEST_UNZIPPED\" \\\n",
        "    --artifact_root \"$ROOT_ARTIFACT_SAVE\" \\\n",
        "    --model_type \"VIT_S16\" \\\n",
        "    --batch_size 64 \\\n",
        "    --n_epochs 100 \\\n",
        "    --num_workers 12 \\\n",
        "    --out_model_name \"vit_s16_moco_encoder_v1.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuRzJCxq3Ecm",
        "outputId": "aaacba78-25bd-4c49-be5e-51e84c00c770"
      },
      "id": "AuRzJCxq3Ecm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created log file:  /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline/moco_training_log_20251209_123855.txt\n",
            "[2025-12-09 12:38:55] Creating MoCo medical image Train DataLoader... : from /content/drive/MyDrive/ViT_MoCo_Project/Data/1_final_project_updated_names_train_moco.csv\n",
            "Loading dataset from: /content/drive/MyDrive/ViT_MoCo_Project/Data/1_final_project_updated_names_train_moco.csv\n",
            "Training Dataset size: 49500 images\n",
            "[2025-12-09 12:38:57] Using backbone: VIT_S16\n",
            "Using timm ViT backbone: vit_small_patch16_224\n",
            "[2025-12-09 12:38:58] Starting Unified MoCo training for 100 epochs...\n",
            "[2025-12-09 12:38:58] Precision mode = fp16\n",
            "Epoch 0/99:   0% 0/773 [00:00<?, ?it/s]/content/drive/MyDrive/ViT_MoCo_Project/src/moco/train_moco_unified.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(dtype=dtype_autocast):\n",
            "Epoch 0/99: 100% 773/773 [03:37<00:00,  3.55it/s, loss=6.2, pos_cos=0.998]\n",
            "[2025-12-09 12:42:35] Epoch complete 0, Avg. Running Loss: 6.435738\n",
            "[2025-12-09 12:42:35] POS_COS=0.9503\n",
            "[2025-12-09 12:42:35] Saving initial checkpoint at epoch 1; Avg. Running Loss: 6.435738\n",
            "[2025-12-09 12:42:50] Saving checkpoint at epoch 1; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_1.pth\n",
            "Epoch 1/99: 100% 773/773 [03:45<00:00,  3.43it/s, loss=6.19, pos_cos=0.999]\n",
            "[2025-12-09 12:46:36] Epoch complete 1, Avg. Running Loss: 6.191602\n",
            "[2025-12-09 12:46:36] POS_COS=0.9992\n",
            "[2025-12-09 12:46:36] Loss improved from 6.435738 to 6.191602. Saving checkpoint.\n",
            "[2025-12-09 12:46:37] Saving checkpoint at epoch 2; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_2.pth\n",
            "Epoch 2/99: 100% 773/773 [03:45<00:00,  3.43it/s, loss=6.19, pos_cos=0.999]\n",
            "[2025-12-09 12:50:23] Epoch complete 2, Avg. Running Loss: 6.189332\n",
            "[2025-12-09 12:50:23] POS_COS=0.9994\n",
            "[2025-12-09 12:50:23] Loss improved from 6.191602 to 6.189332. Saving checkpoint.\n",
            "[2025-12-09 12:50:23] Saving checkpoint at epoch 3; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_3.pth\n",
            "Epoch 3/99: 100% 773/773 [03:43<00:00,  3.45it/s, loss=6.19, pos_cos=1]\n",
            "[2025-12-09 12:54:07] Epoch complete 3, Avg. Running Loss: 6.186123\n",
            "[2025-12-09 12:54:07] POS_COS=0.9995\n",
            "[2025-12-09 12:54:07] Loss improved from 6.189332 to 6.186123. Saving checkpoint.\n",
            "[2025-12-09 12:54:08] Saving checkpoint at epoch 4; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_4.pth\n",
            "Epoch 4/99: 100% 773/773 [03:37<00:00,  3.55it/s, loss=6.19, pos_cos=0.999]\n",
            "[2025-12-09 12:57:46] Epoch complete 4, Avg. Running Loss: 6.186046\n",
            "[2025-12-09 12:57:46] POS_COS=0.9995\n",
            "[2025-12-09 12:57:46] Loss improved from 6.186123 to 6.186046. Saving checkpoint.\n",
            "[2025-12-09 12:57:46] Saving checkpoint at epoch 5; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_5.pth\n",
            "Epoch 5/99: 100% 773/773 [03:40<00:00,  3.51it/s, loss=6.19, pos_cos=0.999]\n",
            "[2025-12-09 13:01:27] Epoch complete 5, Avg. Running Loss: 6.186492\n",
            "[2025-12-09 13:01:27] POS_COS=0.9994\n",
            "Epoch 6/99: 100% 773/773 [03:40<00:00,  3.51it/s, loss=6.19, pos_cos=0.999]\n",
            "[2025-12-09 13:05:07] Epoch complete 6, Avg. Running Loss: 6.188360\n",
            "[2025-12-09 13:05:07] POS_COS=0.9991\n",
            "Epoch 7/99: 100% 773/773 [03:42<00:00,  3.48it/s, loss=6.18, pos_cos=1]\n",
            "[2025-12-09 13:08:49] Epoch complete 7, Avg. Running Loss: 6.191447\n",
            "[2025-12-09 13:08:49] POS_COS=0.9981\n",
            "Epoch 8/99: 100% 773/773 [03:45<00:00,  3.43it/s, loss=6.18, pos_cos=1]\n",
            "[2025-12-09 13:12:35] Epoch complete 8, Avg. Running Loss: 6.180980\n",
            "[2025-12-09 13:12:35] POS_COS=0.9998\n",
            "[2025-12-09 13:12:35] Loss improved from 6.186046 to 6.180980. Saving checkpoint.\n",
            "[2025-12-09 13:12:35] Saving checkpoint at epoch 9; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_9.pth\n",
            "Epoch 9/99: 100% 773/773 [03:45<00:00,  3.43it/s, loss=6.18, pos_cos=1]\n",
            "[2025-12-09 13:16:21] Epoch complete 9, Avg. Running Loss: 6.180055\n",
            "[2025-12-09 13:16:21] POS_COS=0.9999\n",
            "[2025-12-09 13:16:21] Loss improved from 6.180980 to 6.180055. Saving checkpoint.\n",
            "[2025-12-09 13:16:22] Saving checkpoint at epoch 10; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_10.pth\n",
            "Epoch 10/99: 100% 773/773 [03:39<00:00,  3.52it/s, loss=6.18, pos_cos=1]\n",
            "[2025-12-09 13:20:02] Epoch complete 10, Avg. Running Loss: 6.179734\n",
            "[2025-12-09 13:20:02] POS_COS=1.0000\n",
            "[2025-12-09 13:20:02] Loss improved from 6.180055 to 6.179734. Saving checkpoint.\n",
            "[2025-12-09 13:20:03] Saving checkpoint at epoch 11; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_11.pth\n",
            "Epoch 11/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.18, pos_cos=1]\n",
            "[2025-12-09 13:23:44] Epoch complete 11, Avg. Running Loss: 6.180119\n",
            "[2025-12-09 13:23:44] POS_COS=0.9999\n",
            "Epoch 12/99: 100% 773/773 [03:45<00:00,  3.43it/s, loss=6.18, pos_cos=0.999]\n",
            "[2025-12-09 13:27:30] Epoch complete 12, Avg. Running Loss: 6.181391\n",
            "[2025-12-09 13:27:30] POS_COS=0.9997\n",
            "Epoch 13/99: 100% 773/773 [03:42<00:00,  3.48it/s, loss=6.19, pos_cos=0.998]\n",
            "[2025-12-09 13:31:12] Epoch complete 13, Avg. Running Loss: 6.185387\n",
            "[2025-12-09 13:31:12] POS_COS=0.9987\n",
            "Epoch 14/99: 100% 773/773 [03:35<00:00,  3.59it/s, loss=6.2, pos_cos=0.995]\n",
            "[2025-12-09 13:34:48] Epoch complete 14, Avg. Running Loss: 6.193348\n",
            "[2025-12-09 13:34:48] POS_COS=0.9968\n",
            "[2025-12-09 13:34:48] Loss improved from 6.179734 to 6.193348. Saving checkpoint.\n",
            "[2025-12-09 13:34:49] Saving checkpoint at epoch 15; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_15.pth\n",
            "Epoch 15/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.21, pos_cos=0.992]\n",
            "[2025-12-09 13:38:30] Epoch complete 15, Avg. Running Loss: 6.206834\n",
            "[2025-12-09 13:38:30] POS_COS=0.9940\n",
            "Epoch 16/99: 100% 773/773 [03:44<00:00,  3.44it/s, loss=6.23, pos_cos=0.99]\n",
            "[2025-12-09 13:42:15] Epoch complete 16, Avg. Running Loss: 6.223626\n",
            "[2025-12-09 13:42:15] POS_COS=0.9906\n",
            "Epoch 17/99: 100% 773/773 [03:46<00:00,  3.41it/s, loss=6.23, pos_cos=0.988]\n",
            "[2025-12-09 13:46:02] Epoch complete 17, Avg. Running Loss: 6.239226\n",
            "[2025-12-09 13:46:02] POS_COS=0.9875\n",
            "Epoch 18/99: 100% 773/773 [03:36<00:00,  3.58it/s, loss=6.25, pos_cos=0.985]\n",
            "[2025-12-09 13:49:38] Epoch complete 18, Avg. Running Loss: 6.251410\n",
            "[2025-12-09 13:49:38] POS_COS=0.9851\n",
            "Epoch 19/99: 100% 773/773 [03:46<00:00,  3.42it/s, loss=6.26, pos_cos=0.984]\n",
            "[2025-12-09 13:53:24] Epoch complete 19, Avg. Running Loss: 6.261820\n",
            "[2025-12-09 13:53:24] POS_COS=0.9830\n",
            "[2025-12-09 13:53:24] Loss improved from 6.193348 to 6.261820. Saving checkpoint.\n",
            "[2025-12-09 13:53:25] Saving checkpoint at epoch 20; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_20.pth\n",
            "Epoch 20/99: 100% 773/773 [03:45<00:00,  3.43it/s, loss=6.29, pos_cos=0.978]\n",
            "[2025-12-09 13:57:10] Epoch complete 20, Avg. Running Loss: 6.293951\n",
            "[2025-12-09 13:57:10] POS_COS=0.9766\n",
            "Epoch 21/99: 100% 773/773 [03:36<00:00,  3.58it/s, loss=6.29, pos_cos=0.977]\n",
            "[2025-12-09 14:00:46] Epoch complete 21, Avg. Running Loss: 6.295904\n",
            "[2025-12-09 14:00:46] POS_COS=0.9761\n",
            "Epoch 22/99: 100% 773/773 [03:43<00:00,  3.46it/s, loss=6.31, pos_cos=0.974]\n",
            "[2025-12-09 14:04:29] Epoch complete 22, Avg. Running Loss: 6.327179\n",
            "[2025-12-09 14:04:29] POS_COS=0.9699\n",
            "Epoch 23/99: 100% 773/773 [03:39<00:00,  3.52it/s, loss=6.33, pos_cos=0.97]\n",
            "[2025-12-09 14:08:09] Epoch complete 23, Avg. Running Loss: 6.321233\n",
            "[2025-12-09 14:08:09] POS_COS=0.9711\n",
            "Epoch 24/99: 100% 773/773 [03:45<00:00,  3.43it/s, loss=6.38, pos_cos=0.96]\n",
            "[2025-12-09 14:11:54] Epoch complete 24, Avg. Running Loss: 6.306397\n",
            "[2025-12-09 14:11:54] POS_COS=0.9740\n",
            "[2025-12-09 14:11:54] Loss improved from 6.261820 to 6.306397. Saving checkpoint.\n",
            "[2025-12-09 14:11:55] Saving checkpoint at epoch 25; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_25.pth\n",
            "Epoch 25/99: 100% 773/773 [03:47<00:00,  3.40it/s, loss=6.4, pos_cos=0.956]\n",
            "[2025-12-09 14:15:43] Epoch complete 25, Avg. Running Loss: 6.328855\n",
            "[2025-12-09 14:15:43] POS_COS=0.9696\n",
            "Epoch 26/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.25, pos_cos=0.986]\n",
            "[2025-12-09 14:19:24] Epoch complete 26, Avg. Running Loss: 6.331700\n",
            "[2025-12-09 14:19:24] POS_COS=0.9690\n",
            "Epoch 27/99: 100% 773/773 [03:35<00:00,  3.58it/s, loss=6.38, pos_cos=0.959]\n",
            "[2025-12-09 14:23:00] Epoch complete 27, Avg. Running Loss: 6.327246\n",
            "[2025-12-09 14:23:00] POS_COS=0.9698\n",
            "Epoch 28/99: 100% 773/773 [03:38<00:00,  3.53it/s, loss=6.28, pos_cos=0.979]\n",
            "[2025-12-09 14:26:39] Epoch complete 28, Avg. Running Loss: 6.344281\n",
            "[2025-12-09 14:26:39] POS_COS=0.9664\n",
            "Epoch 29/99: 100% 773/773 [03:38<00:00,  3.55it/s, loss=6.36, pos_cos=0.964]\n",
            "[2025-12-09 14:30:17] Epoch complete 29, Avg. Running Loss: 6.330361\n",
            "[2025-12-09 14:30:17] POS_COS=0.9691\n",
            "[2025-12-09 14:30:17] Loss improved from 6.306397 to 6.330361. Saving checkpoint.\n",
            "[2025-12-09 14:30:18] Saving checkpoint at epoch 30; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_30.pth\n",
            "Epoch 30/99: 100% 773/773 [03:42<00:00,  3.47it/s, loss=6.23, pos_cos=0.99]\n",
            "[2025-12-09 14:34:01] Epoch complete 30, Avg. Running Loss: 6.278921\n",
            "[2025-12-09 14:34:01] POS_COS=0.9793\n",
            "[2025-12-09 14:34:01] Loss improved from 6.330361 to 6.278921. Saving checkpoint.\n",
            "[2025-12-09 14:34:02] Saving checkpoint at epoch 31; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_31.pth\n",
            "Epoch 31/99: 100% 773/773 [03:37<00:00,  3.55it/s, loss=6.27, pos_cos=0.98]\n",
            "[2025-12-09 14:37:39] Epoch complete 31, Avg. Running Loss: 6.259102\n",
            "[2025-12-09 14:37:39] POS_COS=0.9832\n",
            "[2025-12-09 14:37:39] Loss improved from 6.278921 to 6.259102. Saving checkpoint.\n",
            "[2025-12-09 14:37:40] Saving checkpoint at epoch 32; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_32.pth\n",
            "Epoch 32/99: 100% 773/773 [03:37<00:00,  3.56it/s, loss=6.28, pos_cos=0.979]\n",
            "[2025-12-09 14:41:17] Epoch complete 32, Avg. Running Loss: 6.263755\n",
            "[2025-12-09 14:41:17] POS_COS=0.9822\n",
            "Epoch 33/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.21, pos_cos=0.993]\n",
            "[2025-12-09 14:44:59] Epoch complete 33, Avg. Running Loss: 6.247584\n",
            "[2025-12-09 14:44:59] POS_COS=0.9852\n",
            "[2025-12-09 14:44:59] Loss improved from 6.259102 to 6.247584. Saving checkpoint.\n",
            "[2025-12-09 14:45:00] Saving checkpoint at epoch 34; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_34.pth\n",
            "Epoch 34/99: 100% 773/773 [03:47<00:00,  3.40it/s, loss=6.19, pos_cos=0.997]\n",
            "[2025-12-09 14:48:47] Epoch complete 34, Avg. Running Loss: 6.243878\n",
            "[2025-12-09 14:48:47] POS_COS=0.9858\n",
            "[2025-12-09 14:48:47] Loss improved from 6.247584 to 6.243878. Saving checkpoint.\n",
            "[2025-12-09 14:48:48] Saving checkpoint at epoch 35; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_35.pth\n",
            "Epoch 35/99: 100% 773/773 [03:43<00:00,  3.47it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 14:52:31] Epoch complete 35, Avg. Running Loss: 6.252475\n",
            "[2025-12-09 14:52:31] POS_COS=0.9841\n",
            "Epoch 36/99: 100% 773/773 [03:42<00:00,  3.48it/s, loss=6.28, pos_cos=0.979]\n",
            "[2025-12-09 14:56:14] Epoch complete 36, Avg. Running Loss: 6.261577\n",
            "[2025-12-09 14:56:14] POS_COS=0.9823\n",
            "Epoch 37/99: 100% 773/773 [03:36<00:00,  3.57it/s, loss=6.53, pos_cos=0.929]\n",
            "[2025-12-09 14:59:50] Epoch complete 37, Avg. Running Loss: 6.261921\n",
            "[2025-12-09 14:59:50] POS_COS=0.9822\n",
            "Epoch 38/99: 100% 773/773 [03:38<00:00,  3.55it/s, loss=6.27, pos_cos=0.981]\n",
            "[2025-12-09 15:03:28] Epoch complete 38, Avg. Running Loss: 6.261120\n",
            "[2025-12-09 15:03:28] POS_COS=0.9824\n",
            "Epoch 39/99: 100% 773/773 [03:39<00:00,  3.53it/s, loss=6.28, pos_cos=0.979]\n",
            "[2025-12-09 15:07:07] Epoch complete 39, Avg. Running Loss: 6.281057\n",
            "[2025-12-09 15:07:07] POS_COS=0.9785\n",
            "[2025-12-09 15:07:07] Loss improved from 6.243878 to 6.281057. Saving checkpoint.\n",
            "[2025-12-09 15:07:08] Saving checkpoint at epoch 40; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_40.pth\n",
            "Epoch 40/99: 100% 773/773 [03:41<00:00,  3.50it/s, loss=6.32, pos_cos=0.97]\n",
            "[2025-12-09 15:10:49] Epoch complete 40, Avg. Running Loss: 6.279374\n",
            "[2025-12-09 15:10:49] POS_COS=0.9788\n",
            "[2025-12-09 15:10:49] Loss improved from 6.281057 to 6.279374. Saving checkpoint.\n",
            "[2025-12-09 15:10:50] Saving checkpoint at epoch 41; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_41.pth\n",
            "Epoch 41/99: 100% 773/773 [03:37<00:00,  3.56it/s, loss=6.21, pos_cos=0.994]\n",
            "[2025-12-09 15:14:27] Epoch complete 41, Avg. Running Loss: 6.254235\n",
            "[2025-12-09 15:14:27] POS_COS=0.9838\n",
            "[2025-12-09 15:14:27] Loss improved from 6.279374 to 6.254235. Saving checkpoint.\n",
            "[2025-12-09 15:14:28] Saving checkpoint at epoch 42; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_42.pth\n",
            "Epoch 42/99: 100% 773/773 [03:37<00:00,  3.55it/s, loss=6.22, pos_cos=0.991]\n",
            "[2025-12-09 15:18:06] Epoch complete 42, Avg. Running Loss: 6.240580\n",
            "[2025-12-09 15:18:06] POS_COS=0.9865\n",
            "[2025-12-09 15:18:06] Loss improved from 6.254235 to 6.240580. Saving checkpoint.\n",
            "[2025-12-09 15:18:07] Saving checkpoint at epoch 43; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_43.pth\n",
            "Epoch 43/99: 100% 773/773 [03:41<00:00,  3.48it/s, loss=6.38, pos_cos=0.959]\n",
            "[2025-12-09 15:21:49] Epoch complete 43, Avg. Running Loss: 6.234105\n",
            "[2025-12-09 15:21:49] POS_COS=0.9878\n",
            "[2025-12-09 15:21:49] Loss improved from 6.240580 to 6.234105. Saving checkpoint.\n",
            "[2025-12-09 15:21:50] Saving checkpoint at epoch 44; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_44.pth\n",
            "Epoch 44/99: 100% 773/773 [03:40<00:00,  3.50it/s, loss=6.26, pos_cos=0.983]\n",
            "[2025-12-09 15:25:31] Epoch complete 44, Avg. Running Loss: 6.232145\n",
            "[2025-12-09 15:25:31] POS_COS=0.9882\n",
            "[2025-12-09 15:25:31] Loss improved from 6.234105 to 6.232145. Saving checkpoint.\n",
            "[2025-12-09 15:25:31] Saving checkpoint at epoch 45; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_45.pth\n",
            "Epoch 45/99: 100% 773/773 [03:43<00:00,  3.46it/s, loss=6.32, pos_cos=0.97]\n",
            "[2025-12-09 15:29:15] Epoch complete 45, Avg. Running Loss: 6.235783\n",
            "[2025-12-09 15:29:15] POS_COS=0.9874\n",
            "Epoch 46/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.25, pos_cos=0.985]\n",
            "[2025-12-09 15:32:57] Epoch complete 46, Avg. Running Loss: 6.246140\n",
            "[2025-12-09 15:32:57] POS_COS=0.9853\n",
            "Epoch 47/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.19, pos_cos=0.998]\n",
            "[2025-12-09 15:36:38] Epoch complete 47, Avg. Running Loss: 6.231273\n",
            "[2025-12-09 15:36:38] POS_COS=0.9883\n",
            "[2025-12-09 15:36:38] Loss improved from 6.232145 to 6.231273. Saving checkpoint.\n",
            "[2025-12-09 15:36:39] Saving checkpoint at epoch 48; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_48.pth\n",
            "Epoch 48/99: 100% 773/773 [03:43<00:00,  3.45it/s, loss=6.18, pos_cos=1]\n",
            "[2025-12-09 15:40:23] Epoch complete 48, Avg. Running Loss: 6.238782\n",
            "[2025-12-09 15:40:23] POS_COS=0.9868\n",
            "Epoch 49/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.22, pos_cos=0.991]\n",
            "[2025-12-09 15:44:05] Epoch complete 49, Avg. Running Loss: 6.233980\n",
            "[2025-12-09 15:44:05] POS_COS=0.9878\n",
            "[2025-12-09 15:44:05] Loss improved from 6.231273 to 6.233980. Saving checkpoint.\n",
            "[2025-12-09 15:44:06] Saving checkpoint at epoch 50; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_50.pth\n",
            "Epoch 50/99: 100% 773/773 [03:45<00:00,  3.43it/s, loss=6.29, pos_cos=0.977]\n",
            "[2025-12-09 15:47:51] Epoch complete 50, Avg. Running Loss: 6.238999\n",
            "[2025-12-09 15:47:51] POS_COS=0.9868\n",
            "Epoch 51/99: 100% 773/773 [03:36<00:00,  3.58it/s, loss=6.19, pos_cos=0.998]\n",
            "[2025-12-09 15:51:27] Epoch complete 51, Avg. Running Loss: 6.241187\n",
            "[2025-12-09 15:51:27] POS_COS=0.9863\n",
            "Epoch 52/99: 100% 773/773 [03:40<00:00,  3.50it/s, loss=6.24, pos_cos=0.985]\n",
            "[2025-12-09 15:55:08] Epoch complete 52, Avg. Running Loss: 6.241578\n",
            "[2025-12-09 15:55:08] POS_COS=0.9863\n",
            "Epoch 53/99: 100% 773/773 [03:39<00:00,  3.52it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 15:58:48] Epoch complete 53, Avg. Running Loss: 6.234450\n",
            "[2025-12-09 15:58:48] POS_COS=0.9876\n",
            "Epoch 54/99: 100% 773/773 [03:38<00:00,  3.55it/s, loss=6.2, pos_cos=0.994]\n",
            "[2025-12-09 16:02:26] Epoch complete 54, Avg. Running Loss: 6.227082\n",
            "[2025-12-09 16:02:26] POS_COS=0.9891\n",
            "[2025-12-09 16:02:26] Loss improved from 6.233980 to 6.227082. Saving checkpoint.\n",
            "[2025-12-09 16:02:27] Saving checkpoint at epoch 55; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_55.pth\n",
            "Epoch 55/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.26, pos_cos=0.983]\n",
            "[2025-12-09 16:06:08] Epoch complete 55, Avg. Running Loss: 6.222187\n",
            "[2025-12-09 16:06:08] POS_COS=0.9901\n",
            "[2025-12-09 16:06:08] Loss improved from 6.227082 to 6.222187. Saving checkpoint.\n",
            "[2025-12-09 16:06:09] Saving checkpoint at epoch 56; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_56.pth\n",
            "Epoch 56/99: 100% 773/773 [03:52<00:00,  3.32it/s, loss=6.18, pos_cos=1]\n",
            "[2025-12-09 16:10:02] Epoch complete 56, Avg. Running Loss: 6.221954\n",
            "[2025-12-09 16:10:02] POS_COS=0.9901\n",
            "[2025-12-09 16:10:02] Loss improved from 6.222187 to 6.221954. Saving checkpoint.\n",
            "[2025-12-09 16:10:03] Saving checkpoint at epoch 57; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_57.pth\n",
            "Epoch 57/99: 100% 773/773 [03:47<00:00,  3.39it/s, loss=6.21, pos_cos=0.993]\n",
            "[2025-12-09 16:13:51] Epoch complete 57, Avg. Running Loss: 6.218101\n",
            "[2025-12-09 16:13:51] POS_COS=0.9909\n",
            "[2025-12-09 16:13:51] Loss improved from 6.221954 to 6.218101. Saving checkpoint.\n",
            "[2025-12-09 16:13:52] Saving checkpoint at epoch 58; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_58.pth\n",
            "Epoch 58/99: 100% 773/773 [03:41<00:00,  3.48it/s, loss=6.17, pos_cos=0.999]\n",
            "[2025-12-09 16:17:34] Epoch complete 58, Avg. Running Loss: 6.212848\n",
            "[2025-12-09 16:17:34] POS_COS=0.9919\n",
            "[2025-12-09 16:17:34] Loss improved from 6.218101 to 6.212848. Saving checkpoint.\n",
            "[2025-12-09 16:17:34] Saving checkpoint at epoch 59; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_59.pth\n",
            "Epoch 59/99: 100% 773/773 [03:43<00:00,  3.46it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 16:21:18] Epoch complete 59, Avg. Running Loss: 6.211277\n",
            "[2025-12-09 16:21:18] POS_COS=0.9922\n",
            "[2025-12-09 16:21:18] Loss improved from 6.212848 to 6.211277. Saving checkpoint.\n",
            "[2025-12-09 16:21:19] Saving checkpoint at epoch 60; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_60.pth\n",
            "Epoch 60/99: 100% 773/773 [03:37<00:00,  3.55it/s, loss=6.18, pos_cos=1]\n",
            "[2025-12-09 16:24:56] Epoch complete 60, Avg. Running Loss: 6.209759\n",
            "[2025-12-09 16:24:56] POS_COS=0.9925\n",
            "[2025-12-09 16:24:56] Loss improved from 6.211277 to 6.209759. Saving checkpoint.\n",
            "[2025-12-09 16:24:57] Saving checkpoint at epoch 61; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_61.pth\n",
            "Epoch 61/99: 100% 773/773 [03:42<00:00,  3.47it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 16:28:40] Epoch complete 61, Avg. Running Loss: 6.212297\n",
            "[2025-12-09 16:28:40] POS_COS=0.9919\n",
            "Epoch 62/99: 100% 773/773 [03:35<00:00,  3.59it/s, loss=6.18, pos_cos=0.999]\n",
            "[2025-12-09 16:32:15] Epoch complete 62, Avg. Running Loss: 6.216020\n",
            "[2025-12-09 16:32:15] POS_COS=0.9912\n",
            "Epoch 63/99: 100% 773/773 [03:38<00:00,  3.54it/s, loss=6.23, pos_cos=0.989]\n",
            "[2025-12-09 16:35:54] Epoch complete 63, Avg. Running Loss: 6.211960\n",
            "[2025-12-09 16:35:54] POS_COS=0.9920\n",
            "Epoch 64/99: 100% 773/773 [03:38<00:00,  3.55it/s, loss=6.18, pos_cos=0.999]\n",
            "[2025-12-09 16:39:32] Epoch complete 64, Avg. Running Loss: 6.209292\n",
            "[2025-12-09 16:39:32] POS_COS=0.9925\n",
            "[2025-12-09 16:39:32] Loss improved from 6.209759 to 6.209292. Saving checkpoint.\n",
            "[2025-12-09 16:39:33] Saving checkpoint at epoch 65; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_65.pth\n",
            "Epoch 65/99: 100% 773/773 [03:40<00:00,  3.51it/s, loss=6.18, pos_cos=0.997]\n",
            "[2025-12-09 16:43:13] Epoch complete 65, Avg. Running Loss: 6.203174\n",
            "[2025-12-09 16:43:13] POS_COS=0.9937\n",
            "[2025-12-09 16:43:13] Loss improved from 6.209292 to 6.203174. Saving checkpoint.\n",
            "[2025-12-09 16:43:14] Saving checkpoint at epoch 66; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_66.pth\n",
            "Epoch 66/99: 100% 773/773 [03:44<00:00,  3.44it/s, loss=6.22, pos_cos=0.991]\n",
            "[2025-12-09 16:46:59] Epoch complete 66, Avg. Running Loss: 6.201995\n",
            "[2025-12-09 16:46:59] POS_COS=0.9939\n",
            "[2025-12-09 16:46:59] Loss improved from 6.203174 to 6.201995. Saving checkpoint.\n",
            "[2025-12-09 16:46:59] Saving checkpoint at epoch 67; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_67.pth\n",
            "Epoch 67/99: 100% 773/773 [03:36<00:00,  3.57it/s, loss=6.18, pos_cos=0.999]\n",
            "[2025-12-09 16:50:36] Epoch complete 67, Avg. Running Loss: 6.196734\n",
            "[2025-12-09 16:50:36] POS_COS=0.9949\n",
            "[2025-12-09 16:50:36] Loss improved from 6.201995 to 6.196734. Saving checkpoint.\n",
            "[2025-12-09 16:50:37] Saving checkpoint at epoch 68; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_68.pth\n",
            "Epoch 68/99: 100% 773/773 [03:40<00:00,  3.50it/s, loss=6.29, pos_cos=0.976]\n",
            "[2025-12-09 16:54:18] Epoch complete 68, Avg. Running Loss: 6.195275\n",
            "[2025-12-09 16:54:18] POS_COS=0.9952\n",
            "[2025-12-09 16:54:18] Loss improved from 6.196734 to 6.195275. Saving checkpoint.\n",
            "[2025-12-09 16:54:18] Saving checkpoint at epoch 69; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_69.pth\n",
            "Epoch 69/99: 100% 773/773 [03:50<00:00,  3.35it/s, loss=6.19, pos_cos=0.997]\n",
            "[2025-12-09 16:58:09] Epoch complete 69, Avg. Running Loss: 6.196071\n",
            "[2025-12-09 16:58:09] POS_COS=0.9950\n",
            "[2025-12-09 16:58:09] Loss improved from 6.195275 to 6.196071. Saving checkpoint.\n",
            "[2025-12-09 16:58:10] Saving checkpoint at epoch 70; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_70.pth\n",
            "Epoch 70/99: 100% 773/773 [03:42<00:00,  3.47it/s, loss=6.17, pos_cos=0.999]\n",
            "[2025-12-09 17:01:52] Epoch complete 70, Avg. Running Loss: 6.194002\n",
            "[2025-12-09 17:01:52] POS_COS=0.9954\n",
            "[2025-12-09 17:01:52] Loss improved from 6.196071 to 6.194002. Saving checkpoint.\n",
            "[2025-12-09 17:01:53] Saving checkpoint at epoch 71; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_71.pth\n",
            "Epoch 71/99: 100% 773/773 [03:44<00:00,  3.44it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 17:05:38] Epoch complete 71, Avg. Running Loss: 6.189840\n",
            "[2025-12-09 17:05:38] POS_COS=0.9962\n",
            "[2025-12-09 17:05:38] Loss improved from 6.194002 to 6.189840. Saving checkpoint.\n",
            "[2025-12-09 17:05:39] Saving checkpoint at epoch 72; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_72.pth\n",
            "Epoch 72/99: 100% 773/773 [03:44<00:00,  3.45it/s, loss=6.2, pos_cos=0.994]\n",
            "[2025-12-09 17:09:23] Epoch complete 72, Avg. Running Loss: 6.194142\n",
            "[2025-12-09 17:09:23] POS_COS=0.9953\n",
            "Epoch 73/99: 100% 773/773 [03:43<00:00,  3.46it/s, loss=6.17, pos_cos=0.999]\n",
            "[2025-12-09 17:13:06] Epoch complete 73, Avg. Running Loss: 6.192716\n",
            "[2025-12-09 17:13:06] POS_COS=0.9956\n",
            "Epoch 74/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.2, pos_cos=0.995]\n",
            "[2025-12-09 17:16:48] Epoch complete 74, Avg. Running Loss: 6.189138\n",
            "[2025-12-09 17:16:48] POS_COS=0.9963\n",
            "[2025-12-09 17:16:48] Loss improved from 6.189840 to 6.189138. Saving checkpoint.\n",
            "[2025-12-09 17:16:48] Saving checkpoint at epoch 75; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_75.pth\n",
            "Epoch 75/99: 100% 773/773 [03:37<00:00,  3.55it/s, loss=6.21, pos_cos=0.992]\n",
            "[2025-12-09 17:20:26] Epoch complete 75, Avg. Running Loss: 6.187446\n",
            "[2025-12-09 17:20:26] POS_COS=0.9966\n",
            "[2025-12-09 17:20:26] Loss improved from 6.189138 to 6.187446. Saving checkpoint.\n",
            "[2025-12-09 17:20:27] Saving checkpoint at epoch 76; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_76.pth\n",
            "Epoch 76/99: 100% 773/773 [03:46<00:00,  3.41it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 17:24:14] Epoch complete 76, Avg. Running Loss: 6.188573\n",
            "[2025-12-09 17:24:14] POS_COS=0.9963\n",
            "Epoch 77/99: 100% 773/773 [03:30<00:00,  3.67it/s, loss=6.18, pos_cos=0.999]\n",
            "[2025-12-09 17:27:44] Epoch complete 77, Avg. Running Loss: 6.186782\n",
            "[2025-12-09 17:27:44] POS_COS=0.9967\n",
            "[2025-12-09 17:27:44] Loss improved from 6.187446 to 6.186782. Saving checkpoint.\n",
            "[2025-12-09 17:27:45] Saving checkpoint at epoch 78; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_78.pth\n",
            "Epoch 78/99: 100% 773/773 [03:40<00:00,  3.50it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 17:31:26] Epoch complete 78, Avg. Running Loss: 6.184966\n",
            "[2025-12-09 17:31:26] POS_COS=0.9971\n",
            "[2025-12-09 17:31:26] Loss improved from 6.186782 to 6.184966. Saving checkpoint.\n",
            "[2025-12-09 17:31:27] Saving checkpoint at epoch 79; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_79.pth\n",
            "Epoch 79/99: 100% 773/773 [03:39<00:00,  3.52it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 17:35:06] Epoch complete 79, Avg. Running Loss: 6.185463\n",
            "[2025-12-09 17:35:06] POS_COS=0.9970\n",
            "[2025-12-09 17:35:06] Loss improved from 6.184966 to 6.185463. Saving checkpoint.\n",
            "[2025-12-09 17:35:07] Saving checkpoint at epoch 80; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_80.pth\n",
            "Epoch 80/99: 100% 773/773 [03:41<00:00,  3.49it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 17:38:49] Epoch complete 80, Avg. Running Loss: 6.182138\n",
            "[2025-12-09 17:38:49] POS_COS=0.9976\n",
            "[2025-12-09 17:38:49] Loss improved from 6.185463 to 6.182138. Saving checkpoint.\n",
            "[2025-12-09 17:38:50] Saving checkpoint at epoch 81; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_81.pth\n",
            "Epoch 81/99: 100% 773/773 [03:43<00:00,  3.46it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 17:42:33] Epoch complete 81, Avg. Running Loss: 6.181006\n",
            "[2025-12-09 17:42:33] POS_COS=0.9978\n",
            "[2025-12-09 17:42:33] Loss improved from 6.182138 to 6.181006. Saving checkpoint.\n",
            "[2025-12-09 17:42:34] Saving checkpoint at epoch 82; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_82.pth\n",
            "Epoch 82/99: 100% 773/773 [03:44<00:00,  3.45it/s, loss=6.18, pos_cos=0.999]\n",
            "[2025-12-09 17:46:18] Epoch complete 82, Avg. Running Loss: 6.181304\n",
            "[2025-12-09 17:46:18] POS_COS=0.9977\n",
            "Epoch 83/99: 100% 773/773 [03:43<00:00,  3.46it/s, loss=6.17, pos_cos=0.999]\n",
            "[2025-12-09 17:50:02] Epoch complete 83, Avg. Running Loss: 6.180268\n",
            "[2025-12-09 17:50:02] POS_COS=0.9979\n",
            "[2025-12-09 17:50:02] Loss improved from 6.181006 to 6.180268. Saving checkpoint.\n",
            "[2025-12-09 17:50:03] Saving checkpoint at epoch 84; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_84.pth\n",
            "Epoch 84/99: 100% 773/773 [03:46<00:00,  3.41it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 17:53:50] Epoch complete 84, Avg. Running Loss: 6.178552\n",
            "[2025-12-09 17:53:50] POS_COS=0.9982\n",
            "[2025-12-09 17:53:50] Loss improved from 6.180268 to 6.178552. Saving checkpoint.\n",
            "[2025-12-09 17:53:51] Saving checkpoint at epoch 85; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_85.pth\n",
            "Epoch 85/99: 100% 773/773 [03:48<00:00,  3.38it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 17:57:39] Epoch complete 85, Avg. Running Loss: 6.178409\n",
            "[2025-12-09 17:57:39] POS_COS=0.9983\n",
            "[2025-12-09 17:57:39] Loss improved from 6.178552 to 6.178409. Saving checkpoint.\n",
            "[2025-12-09 17:57:40] Saving checkpoint at epoch 86; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_86.pth\n",
            "Epoch 86/99: 100% 773/773 [03:39<00:00,  3.52it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 18:01:19] Epoch complete 86, Avg. Running Loss: 6.177919\n",
            "[2025-12-09 18:01:19] POS_COS=0.9983\n",
            "[2025-12-09 18:01:19] Loss improved from 6.178409 to 6.177919. Saving checkpoint.\n",
            "[2025-12-09 18:01:20] Saving checkpoint at epoch 87; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_87.pth\n",
            "Epoch 87/99: 100% 773/773 [03:42<00:00,  3.47it/s, loss=6.17, pos_cos=0.999]\n",
            "[2025-12-09 18:05:03] Epoch complete 87, Avg. Running Loss: 6.176772\n",
            "[2025-12-09 18:05:03] POS_COS=0.9985\n",
            "[2025-12-09 18:05:03] Loss improved from 6.177919 to 6.176772. Saving checkpoint.\n",
            "[2025-12-09 18:05:04] Saving checkpoint at epoch 88; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_88.pth\n",
            "Epoch 88/99: 100% 773/773 [03:44<00:00,  3.44it/s, loss=6.18, pos_cos=0.999]\n",
            "[2025-12-09 18:08:49] Epoch complete 88, Avg. Running Loss: 6.176110\n",
            "[2025-12-09 18:08:49] POS_COS=0.9986\n",
            "[2025-12-09 18:08:49] Loss improved from 6.176772 to 6.176110. Saving checkpoint.\n",
            "[2025-12-09 18:08:50] Saving checkpoint at epoch 89; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_89.pth\n",
            "Epoch 89/99: 100% 773/773 [03:37<00:00,  3.56it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 18:12:27] Epoch complete 89, Avg. Running Loss: 6.175249\n",
            "[2025-12-09 18:12:27] POS_COS=0.9988\n",
            "[2025-12-09 18:12:27] Loss improved from 6.176110 to 6.175249. Saving checkpoint.\n",
            "[2025-12-09 18:12:28] Saving checkpoint at epoch 90; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_90.pth\n",
            "Epoch 90/99: 100% 773/773 [03:37<00:00,  3.56it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 18:16:05] Epoch complete 90, Avg. Running Loss: 6.175026\n",
            "[2025-12-09 18:16:05] POS_COS=0.9988\n",
            "[2025-12-09 18:16:05] Loss improved from 6.175249 to 6.175026. Saving checkpoint.\n",
            "[2025-12-09 18:16:06] Saving checkpoint at epoch 91; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_91.pth\n",
            "Epoch 91/99: 100% 773/773 [03:31<00:00,  3.65it/s, loss=6.18, pos_cos=0.998]\n",
            "[2025-12-09 18:19:38] Epoch complete 91, Avg. Running Loss: 6.174571\n",
            "[2025-12-09 18:19:38] POS_COS=0.9989\n",
            "[2025-12-09 18:19:38] Loss improved from 6.175026 to 6.174571. Saving checkpoint.\n",
            "[2025-12-09 18:19:38] Saving checkpoint at epoch 92; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_92.pth\n",
            "Epoch 92/99: 100% 773/773 [03:36<00:00,  3.58it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 18:23:14] Epoch complete 92, Avg. Running Loss: 6.174101\n",
            "[2025-12-09 18:23:14] POS_COS=0.9990\n",
            "[2025-12-09 18:23:14] Loss improved from 6.174571 to 6.174101. Saving checkpoint.\n",
            "[2025-12-09 18:23:15] Saving checkpoint at epoch 93; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_93.pth\n",
            "Epoch 93/99: 100% 773/773 [03:43<00:00,  3.45it/s, loss=6.17, pos_cos=0.999]\n",
            "[2025-12-09 18:26:59] Epoch complete 93, Avg. Running Loss: 6.173806\n",
            "[2025-12-09 18:26:59] POS_COS=0.9991\n",
            "[2025-12-09 18:26:59] Loss improved from 6.174101 to 6.173806. Saving checkpoint.\n",
            "[2025-12-09 18:27:00] Saving checkpoint at epoch 94; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_94.pth\n",
            "Epoch 94/99: 100% 773/773 [03:40<00:00,  3.51it/s, loss=6.19, pos_cos=0.997]\n",
            "[2025-12-09 18:30:41] Epoch complete 94, Avg. Running Loss: 6.173225\n",
            "[2025-12-09 18:30:41] POS_COS=0.9992\n",
            "[2025-12-09 18:30:41] Loss improved from 6.173806 to 6.173225. Saving checkpoint.\n",
            "[2025-12-09 18:30:41] Saving checkpoint at epoch 95; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_95.pth\n",
            "Epoch 95/99: 100% 773/773 [03:38<00:00,  3.53it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 18:34:20] Epoch complete 95, Avg. Running Loss: 6.172803\n",
            "[2025-12-09 18:34:20] POS_COS=0.9992\n",
            "[2025-12-09 18:34:20] Loss improved from 6.173225 to 6.172803. Saving checkpoint.\n",
            "[2025-12-09 18:34:21] Saving checkpoint at epoch 96; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_96.pth\n",
            "Epoch 96/99: 100% 773/773 [03:33<00:00,  3.62it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 18:37:55] Epoch complete 96, Avg. Running Loss: 6.171930\n",
            "[2025-12-09 18:37:55] POS_COS=0.9993\n",
            "[2025-12-09 18:37:55] Loss improved from 6.172803 to 6.171930. Saving checkpoint.\n",
            "[2025-12-09 18:37:56] Saving checkpoint at epoch 97; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_97.pth\n",
            "Epoch 97/99: 100% 773/773 [03:43<00:00,  3.46it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 18:41:39] Epoch complete 97, Avg. Running Loss: 6.171570\n",
            "[2025-12-09 18:41:39] POS_COS=0.9994\n",
            "[2025-12-09 18:41:39] Loss improved from 6.171930 to 6.171570. Saving checkpoint.\n",
            "[2025-12-09 18:41:40] Saving checkpoint at epoch 98; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_98.pth\n",
            "Epoch 98/99: 100% 773/773 [03:36<00:00,  3.58it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 18:45:16] Epoch complete 98, Avg. Running Loss: 6.171195\n",
            "[2025-12-09 18:45:16] POS_COS=0.9995\n",
            "[2025-12-09 18:45:16] Loss improved from 6.171570 to 6.171195. Saving checkpoint.\n",
            "[2025-12-09 18:45:17] Saving checkpoint at epoch 99; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_99.pth\n",
            "Epoch 99/99: 100% 773/773 [03:39<00:00,  3.52it/s, loss=6.17, pos_cos=1]\n",
            "[2025-12-09 18:48:57] Epoch complete 99, Avg. Running Loss: 6.171317\n",
            "[2025-12-09 18:48:57] POS_COS=0.9994\n",
            "[2025-12-09 18:48:57] Loss improved from 6.171195 to 6.171317. Saving checkpoint.\n",
            "[2025-12-09 18:48:57] Saving checkpoint at epoch 100; /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//checkpoint_epoch_100.pth\n",
            "[2025-12-09 18:48:57] MoCo training complete!!\n",
            "[2025-12-09 18:48:58] Saved pretrained encoder to /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline/vit_s16_moco_encoder_v1.pth\n",
            "[2025-12-09 18:48:58] Saved training stats to /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_baseline//pretrain_stats_training.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PreNormEncoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, heads, mlp_ratio=4.0, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, heads, dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(int(embed_dim * mlp_ratio), embed_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class SimpleTransformer(nn.Module):\n",
        "    def __init__(self, embed_dim=512, depth=12, heads=8, mlp_ratio=4.0, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            PreNormEncoderLayer(embed_dim, heads, mlp_ratio, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2sXm7sf93blO"
      },
      "id": "2sXm7sf93blO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "vu6akO8jcuJQ",
      "metadata": {
        "id": "vu6akO8jcuJQ"
      },
      "source": [
        "## Test Backbone with Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "meKRfRCScwZ_",
      "metadata": {
        "id": "meKRfRCScwZ_"
      },
      "outputs": [],
      "source": [
        "# Run from the src directory\n",
        "%cd \"/content/drive/MyDrive/ViT_MoCo_Project/src\"\n",
        "\n",
        "# Hyperparams\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DfnlgaWTcy5t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfnlgaWTcy5t",
        "outputId": "b8146fad-d01a-4bd8-923b-eb332c5ced6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created log file:  /content/drive/MyDrive/ViT_MoCo_Project/artifacts/moco_backbone_testing_log_20251207_114444.txt\n",
            "[2025-12-07 11:44:44] Starting MoCo backbone testing...\n",
            "[2025-12-07 11:44:44] Loading pretrained MoCo model from /content/drive/MyDrive/ViT_MoCo_Project/artifacts/vit_hybrid_moco_checkpoint_epoch_37.pth...\n",
            "[2025-12-07 11:44:49] Detected 'model_state' in checkpoint.\n",
            "[2025-12-07 11:44:49] Loaded model. Missing keys: [], unexpected keys: []\n",
            "[2025-12-07 11:44:49] Loaded pretrained encoder. missing keys: [], unexpected: []\n",
            "Loading train dataset...\n",
            "CSV: /content/drive/MyDrive/ViT_MoCo_Project/Data/2_final_project_updated_names_train_linear.csv\n",
            " * Images - Train Root Directory: /tmp/CheXpert_dataset/CheXpert_reduced_dataset_split_v3/train\n",
            "Unique labels in column 'Pneumonia': [1 0]\n",
            "Loading test dataset...\n",
            "CSV: /content/drive/MyDrive/ViT_MoCo_Project/Data/2_final_project_updated_names_test_linear.csv\n",
            " * Images - Test Root Directory: /tmp/CheXpert_dataset/CheXpert_reduced_dataset_split_v3/test\n",
            "Unique labels in column 'Pneumonia': [1 0]\n",
            "[2025-12-07 11:44:49] Starting MoCo backbone testing...\n",
            "Extracting the ViTMoCo model (new architecture)...\n",
            "[2025-12-07 11:44:49] Model Keys: odict_keys(['queue', 'queue_ptr', 'patch_embed.proj.0.weight', 'patch_embed.proj.0.bias', 'patch_embed.proj.2.weight', 'patch_embed.proj.2.bias', 'patch_embed.proj.4.weight', 'patch_embed.proj.4.bias', 'patch_embed.norm.weight', 'patch_embed.norm.bias', 'pos_encoding.pos_embed', 'pos_encoding.cls_token', 'transformer.encoder.layers.0.self_attn.in_proj_weight', 'transformer.encoder.layers.0.self_attn.in_proj_bias', 'transformer.encoder.layers.0.self_attn.out_proj.weight', 'transformer.encoder.layers.0.self_attn.out_proj.bias', 'transformer.encoder.layers.0.linear1.weight', 'transformer.encoder.layers.0.linear1.bias', 'transformer.encoder.layers.0.linear2.weight', 'transformer.encoder.layers.0.linear2.bias', 'transformer.encoder.layers.0.norm1.weight', 'transformer.encoder.layers.0.norm1.bias', 'transformer.encoder.layers.0.norm2.weight', 'transformer.encoder.layers.0.norm2.bias', 'transformer.encoder.layers.1.self_attn.in_proj_weight', 'transformer.encoder.layers.1.self_attn.in_proj_bias', 'transformer.encoder.layers.1.self_attn.out_proj.weight', 'transformer.encoder.layers.1.self_attn.out_proj.bias', 'transformer.encoder.layers.1.linear1.weight', 'transformer.encoder.layers.1.linear1.bias', 'transformer.encoder.layers.1.linear2.weight', 'transformer.encoder.layers.1.linear2.bias', 'transformer.encoder.layers.1.norm1.weight', 'transformer.encoder.layers.1.norm1.bias', 'transformer.encoder.layers.1.norm2.weight', 'transformer.encoder.layers.1.norm2.bias', 'transformer.encoder.layers.2.self_attn.in_proj_weight', 'transformer.encoder.layers.2.self_attn.in_proj_bias', 'transformer.encoder.layers.2.self_attn.out_proj.weight', 'transformer.encoder.layers.2.self_attn.out_proj.bias', 'transformer.encoder.layers.2.linear1.weight', 'transformer.encoder.layers.2.linear1.bias', 'transformer.encoder.layers.2.linear2.weight', 'transformer.encoder.layers.2.linear2.bias', 'transformer.encoder.layers.2.norm1.weight', 'transformer.encoder.layers.2.norm1.bias', 'transformer.encoder.layers.2.norm2.weight', 'transformer.encoder.layers.2.norm2.bias', 'transformer.encoder.layers.3.self_attn.in_proj_weight', 'transformer.encoder.layers.3.self_attn.in_proj_bias', 'transformer.encoder.layers.3.self_attn.out_proj.weight', 'transformer.encoder.layers.3.self_attn.out_proj.bias', 'transformer.encoder.layers.3.linear1.weight', 'transformer.encoder.layers.3.linear1.bias', 'transformer.encoder.layers.3.linear2.weight', 'transformer.encoder.layers.3.linear2.bias', 'transformer.encoder.layers.3.norm1.weight', 'transformer.encoder.layers.3.norm1.bias', 'transformer.encoder.layers.3.norm2.weight', 'transformer.encoder.layers.3.norm2.bias', 'transformer.encoder.layers.4.self_attn.in_proj_weight', 'transformer.encoder.layers.4.self_attn.in_proj_bias', 'transformer.encoder.layers.4.self_attn.out_proj.weight', 'transformer.encoder.layers.4.self_attn.out_proj.bias', 'transformer.encoder.layers.4.linear1.weight', 'transformer.encoder.layers.4.linear1.bias', 'transformer.encoder.layers.4.linear2.weight', 'transformer.encoder.layers.4.linear2.bias', 'transformer.encoder.layers.4.norm1.weight', 'transformer.encoder.layers.4.norm1.bias', 'transformer.encoder.layers.4.norm2.weight', 'transformer.encoder.layers.4.norm2.bias', 'transformer.encoder.layers.5.self_attn.in_proj_weight', 'transformer.encoder.layers.5.self_attn.in_proj_bias', 'transformer.encoder.layers.5.self_attn.out_proj.weight', 'transformer.encoder.layers.5.self_attn.out_proj.bias', 'transformer.encoder.layers.5.linear1.weight', 'transformer.encoder.layers.5.linear1.bias', 'transformer.encoder.layers.5.linear2.weight', 'transformer.encoder.layers.5.linear2.bias', 'transformer.encoder.layers.5.norm1.weight', 'transformer.encoder.layers.5.norm1.bias', 'transformer.encoder.layers.5.norm2.weight', 'transformer.encoder.layers.5.norm2.bias', 'transformer.encoder.layers.6.self_attn.in_proj_weight', 'transformer.encoder.layers.6.self_attn.in_proj_bias', 'transformer.encoder.layers.6.self_attn.out_proj.weight', 'transformer.encoder.layers.6.self_attn.out_proj.bias', 'transformer.encoder.layers.6.linear1.weight', 'transformer.encoder.layers.6.linear1.bias', 'transformer.encoder.layers.6.linear2.weight', 'transformer.encoder.layers.6.linear2.bias', 'transformer.encoder.layers.6.norm1.weight', 'transformer.encoder.layers.6.norm1.bias', 'transformer.encoder.layers.6.norm2.weight', 'transformer.encoder.layers.6.norm2.bias', 'transformer.encoder.layers.7.self_attn.in_proj_weight', 'transformer.encoder.layers.7.self_attn.in_proj_bias', 'transformer.encoder.layers.7.self_attn.out_proj.weight', 'transformer.encoder.layers.7.self_attn.out_proj.bias', 'transformer.encoder.layers.7.linear1.weight', 'transformer.encoder.layers.7.linear1.bias', 'transformer.encoder.layers.7.linear2.weight', 'transformer.encoder.layers.7.linear2.bias', 'transformer.encoder.layers.7.norm1.weight', 'transformer.encoder.layers.7.norm1.bias', 'transformer.encoder.layers.7.norm2.weight', 'transformer.encoder.layers.7.norm2.bias', 'transformer.encoder.layers.8.self_attn.in_proj_weight', 'transformer.encoder.layers.8.self_attn.in_proj_bias', 'transformer.encoder.layers.8.self_attn.out_proj.weight', 'transformer.encoder.layers.8.self_attn.out_proj.bias', 'transformer.encoder.layers.8.linear1.weight', 'transformer.encoder.layers.8.linear1.bias', 'transformer.encoder.layers.8.linear2.weight', 'transformer.encoder.layers.8.linear2.bias', 'transformer.encoder.layers.8.norm1.weight', 'transformer.encoder.layers.8.norm1.bias', 'transformer.encoder.layers.8.norm2.weight', 'transformer.encoder.layers.8.norm2.bias', 'transformer.encoder.layers.9.self_attn.in_proj_weight', 'transformer.encoder.layers.9.self_attn.in_proj_bias', 'transformer.encoder.layers.9.self_attn.out_proj.weight', 'transformer.encoder.layers.9.self_attn.out_proj.bias', 'transformer.encoder.layers.9.linear1.weight', 'transformer.encoder.layers.9.linear1.bias', 'transformer.encoder.layers.9.linear2.weight', 'transformer.encoder.layers.9.linear2.bias', 'transformer.encoder.layers.9.norm1.weight', 'transformer.encoder.layers.9.norm1.bias', 'transformer.encoder.layers.9.norm2.weight', 'transformer.encoder.layers.9.norm2.bias', 'transformer.encoder.layers.10.self_attn.in_proj_weight', 'transformer.encoder.layers.10.self_attn.in_proj_bias', 'transformer.encoder.layers.10.self_attn.out_proj.weight', 'transformer.encoder.layers.10.self_attn.out_proj.bias', 'transformer.encoder.layers.10.linear1.weight', 'transformer.encoder.layers.10.linear1.bias', 'transformer.encoder.layers.10.linear2.weight', 'transformer.encoder.layers.10.linear2.bias', 'transformer.encoder.layers.10.norm1.weight', 'transformer.encoder.layers.10.norm1.bias', 'transformer.encoder.layers.10.norm2.weight', 'transformer.encoder.layers.10.norm2.bias', 'transformer.encoder.layers.11.self_attn.in_proj_weight', 'transformer.encoder.layers.11.self_attn.in_proj_bias', 'transformer.encoder.layers.11.self_attn.out_proj.weight', 'transformer.encoder.layers.11.self_attn.out_proj.bias', 'transformer.encoder.layers.11.linear1.weight', 'transformer.encoder.layers.11.linear1.bias', 'transformer.encoder.layers.11.linear2.weight', 'transformer.encoder.layers.11.linear2.bias', 'transformer.encoder.layers.11.norm1.weight', 'transformer.encoder.layers.11.norm1.bias', 'transformer.encoder.layers.11.norm2.weight', 'transformer.encoder.layers.11.norm2.bias', 'proj_head.mlp.0.weight', 'proj_head.mlp.0.bias', 'proj_head.mlp.2.weight', 'proj_head.mlp.2.bias', 'patch_embed_k.proj.0.weight', 'patch_embed_k.proj.0.bias', 'patch_embed_k.proj.2.weight', 'patch_embed_k.proj.2.bias', 'patch_embed_k.proj.4.weight', 'patch_embed_k.proj.4.bias', 'patch_embed_k.norm.weight', 'patch_embed_k.norm.bias', 'pos_encoding_k.pos_embed', 'pos_encoding_k.cls_token', 'transformer_k.encoder.layers.0.self_attn.in_proj_weight', 'transformer_k.encoder.layers.0.self_attn.in_proj_bias', 'transformer_k.encoder.layers.0.self_attn.out_proj.weight', 'transformer_k.encoder.layers.0.self_attn.out_proj.bias', 'transformer_k.encoder.layers.0.linear1.weight', 'transformer_k.encoder.layers.0.linear1.bias', 'transformer_k.encoder.layers.0.linear2.weight', 'transformer_k.encoder.layers.0.linear2.bias', 'transformer_k.encoder.layers.0.norm1.weight', 'transformer_k.encoder.layers.0.norm1.bias', 'transformer_k.encoder.layers.0.norm2.weight', 'transformer_k.encoder.layers.0.norm2.bias', 'transformer_k.encoder.layers.1.self_attn.in_proj_weight', 'transformer_k.encoder.layers.1.self_attn.in_proj_bias', 'transformer_k.encoder.layers.1.self_attn.out_proj.weight', 'transformer_k.encoder.layers.1.self_attn.out_proj.bias', 'transformer_k.encoder.layers.1.linear1.weight', 'transformer_k.encoder.layers.1.linear1.bias', 'transformer_k.encoder.layers.1.linear2.weight', 'transformer_k.encoder.layers.1.linear2.bias', 'transformer_k.encoder.layers.1.norm1.weight', 'transformer_k.encoder.layers.1.norm1.bias', 'transformer_k.encoder.layers.1.norm2.weight', 'transformer_k.encoder.layers.1.norm2.bias', 'transformer_k.encoder.layers.2.self_attn.in_proj_weight', 'transformer_k.encoder.layers.2.self_attn.in_proj_bias', 'transformer_k.encoder.layers.2.self_attn.out_proj.weight', 'transformer_k.encoder.layers.2.self_attn.out_proj.bias', 'transformer_k.encoder.layers.2.linear1.weight', 'transformer_k.encoder.layers.2.linear1.bias', 'transformer_k.encoder.layers.2.linear2.weight', 'transformer_k.encoder.layers.2.linear2.bias', 'transformer_k.encoder.layers.2.norm1.weight', 'transformer_k.encoder.layers.2.norm1.bias', 'transformer_k.encoder.layers.2.norm2.weight', 'transformer_k.encoder.layers.2.norm2.bias', 'transformer_k.encoder.layers.3.self_attn.in_proj_weight', 'transformer_k.encoder.layers.3.self_attn.in_proj_bias', 'transformer_k.encoder.layers.3.self_attn.out_proj.weight', 'transformer_k.encoder.layers.3.self_attn.out_proj.bias', 'transformer_k.encoder.layers.3.linear1.weight', 'transformer_k.encoder.layers.3.linear1.bias', 'transformer_k.encoder.layers.3.linear2.weight', 'transformer_k.encoder.layers.3.linear2.bias', 'transformer_k.encoder.layers.3.norm1.weight', 'transformer_k.encoder.layers.3.norm1.bias', 'transformer_k.encoder.layers.3.norm2.weight', 'transformer_k.encoder.layers.3.norm2.bias', 'transformer_k.encoder.layers.4.self_attn.in_proj_weight', 'transformer_k.encoder.layers.4.self_attn.in_proj_bias', 'transformer_k.encoder.layers.4.self_attn.out_proj.weight', 'transformer_k.encoder.layers.4.self_attn.out_proj.bias', 'transformer_k.encoder.layers.4.linear1.weight', 'transformer_k.encoder.layers.4.linear1.bias', 'transformer_k.encoder.layers.4.linear2.weight', 'transformer_k.encoder.layers.4.linear2.bias', 'transformer_k.encoder.layers.4.norm1.weight', 'transformer_k.encoder.layers.4.norm1.bias', 'transformer_k.encoder.layers.4.norm2.weight', 'transformer_k.encoder.layers.4.norm2.bias', 'transformer_k.encoder.layers.5.self_attn.in_proj_weight', 'transformer_k.encoder.layers.5.self_attn.in_proj_bias', 'transformer_k.encoder.layers.5.self_attn.out_proj.weight', 'transformer_k.encoder.layers.5.self_attn.out_proj.bias', 'transformer_k.encoder.layers.5.linear1.weight', 'transformer_k.encoder.layers.5.linear1.bias', 'transformer_k.encoder.layers.5.linear2.weight', 'transformer_k.encoder.layers.5.linear2.bias', 'transformer_k.encoder.layers.5.norm1.weight', 'transformer_k.encoder.layers.5.norm1.bias', 'transformer_k.encoder.layers.5.norm2.weight', 'transformer_k.encoder.layers.5.norm2.bias', 'transformer_k.encoder.layers.6.self_attn.in_proj_weight', 'transformer_k.encoder.layers.6.self_attn.in_proj_bias', 'transformer_k.encoder.layers.6.self_attn.out_proj.weight', 'transformer_k.encoder.layers.6.self_attn.out_proj.bias', 'transformer_k.encoder.layers.6.linear1.weight', 'transformer_k.encoder.layers.6.linear1.bias', 'transformer_k.encoder.layers.6.linear2.weight', 'transformer_k.encoder.layers.6.linear2.bias', 'transformer_k.encoder.layers.6.norm1.weight', 'transformer_k.encoder.layers.6.norm1.bias', 'transformer_k.encoder.layers.6.norm2.weight', 'transformer_k.encoder.layers.6.norm2.bias', 'transformer_k.encoder.layers.7.self_attn.in_proj_weight', 'transformer_k.encoder.layers.7.self_attn.in_proj_bias', 'transformer_k.encoder.layers.7.self_attn.out_proj.weight', 'transformer_k.encoder.layers.7.self_attn.out_proj.bias', 'transformer_k.encoder.layers.7.linear1.weight', 'transformer_k.encoder.layers.7.linear1.bias', 'transformer_k.encoder.layers.7.linear2.weight', 'transformer_k.encoder.layers.7.linear2.bias', 'transformer_k.encoder.layers.7.norm1.weight', 'transformer_k.encoder.layers.7.norm1.bias', 'transformer_k.encoder.layers.7.norm2.weight', 'transformer_k.encoder.layers.7.norm2.bias', 'transformer_k.encoder.layers.8.self_attn.in_proj_weight', 'transformer_k.encoder.layers.8.self_attn.in_proj_bias', 'transformer_k.encoder.layers.8.self_attn.out_proj.weight', 'transformer_k.encoder.layers.8.self_attn.out_proj.bias', 'transformer_k.encoder.layers.8.linear1.weight', 'transformer_k.encoder.layers.8.linear1.bias', 'transformer_k.encoder.layers.8.linear2.weight', 'transformer_k.encoder.layers.8.linear2.bias', 'transformer_k.encoder.layers.8.norm1.weight', 'transformer_k.encoder.layers.8.norm1.bias', 'transformer_k.encoder.layers.8.norm2.weight', 'transformer_k.encoder.layers.8.norm2.bias', 'transformer_k.encoder.layers.9.self_attn.in_proj_weight', 'transformer_k.encoder.layers.9.self_attn.in_proj_bias', 'transformer_k.encoder.layers.9.self_attn.out_proj.weight', 'transformer_k.encoder.layers.9.self_attn.out_proj.bias', 'transformer_k.encoder.layers.9.linear1.weight', 'transformer_k.encoder.layers.9.linear1.bias', 'transformer_k.encoder.layers.9.linear2.weight', 'transformer_k.encoder.layers.9.linear2.bias', 'transformer_k.encoder.layers.9.norm1.weight', 'transformer_k.encoder.layers.9.norm1.bias', 'transformer_k.encoder.layers.9.norm2.weight', 'transformer_k.encoder.layers.9.norm2.bias', 'transformer_k.encoder.layers.10.self_attn.in_proj_weight', 'transformer_k.encoder.layers.10.self_attn.in_proj_bias', 'transformer_k.encoder.layers.10.self_attn.out_proj.weight', 'transformer_k.encoder.layers.10.self_attn.out_proj.bias', 'transformer_k.encoder.layers.10.linear1.weight', 'transformer_k.encoder.layers.10.linear1.bias', 'transformer_k.encoder.layers.10.linear2.weight', 'transformer_k.encoder.layers.10.linear2.bias', 'transformer_k.encoder.layers.10.norm1.weight', 'transformer_k.encoder.layers.10.norm1.bias', 'transformer_k.encoder.layers.10.norm2.weight', 'transformer_k.encoder.layers.10.norm2.bias', 'transformer_k.encoder.layers.11.self_attn.in_proj_weight', 'transformer_k.encoder.layers.11.self_attn.in_proj_bias', 'transformer_k.encoder.layers.11.self_attn.out_proj.weight', 'transformer_k.encoder.layers.11.self_attn.out_proj.bias', 'transformer_k.encoder.layers.11.linear1.weight', 'transformer_k.encoder.layers.11.linear1.bias', 'transformer_k.encoder.layers.11.linear2.weight', 'transformer_k.encoder.layers.11.linear2.bias', 'transformer_k.encoder.layers.11.norm1.weight', 'transformer_k.encoder.layers.11.norm1.bias', 'transformer_k.encoder.layers.11.norm2.weight', 'transformer_k.encoder.layers.11.norm2.bias', 'proj_head_k.mlp.0.weight', 'proj_head_k.mlp.0.bias', 'proj_head_k.mlp.2.weight', 'proj_head_k.mlp.2.bias'])\n",
            "[2025-12-07 11:44:49] Starting linear evaluation for 10 epochs...\n",
            "Epoch 0/9: 100% 131/131 [00:26<00:00,  4.90it/s, loss=0.313]\n",
            "[2025-12-07 11:45:47] Epoch 1/10, Avg. Running Loss: 0.630324', Train Acc:67.30% Test Acc: 82.23%\n",
            "Epoch 1/9: 100% 131/131 [00:25<00:00,  5.16it/s, loss=0.368]\n",
            "[2025-12-07 11:46:43] Epoch 2/10, Avg. Running Loss: 0.627119', Train Acc:67.30% Test Acc: 82.23%\n",
            "Epoch 2/9: 100% 131/131 [00:25<00:00,  5.16it/s, loss=0.774]\n",
            "[2025-12-07 11:47:40] Epoch 3/10, Avg. Running Loss: 0.632699', Train Acc:67.30% Test Acc: 82.23%\n",
            "Epoch 3/9: 100% 131/131 [00:25<00:00,  5.15it/s, loss=1.09]\n",
            "[2025-12-07 11:48:36] Epoch 4/10, Avg. Running Loss: 0.633971', Train Acc:67.30% Test Acc: 82.23%\n",
            "Epoch 4/9: 100% 131/131 [00:25<00:00,  5.15it/s, loss=0.65]\n",
            "[2025-12-07 11:49:33] Epoch 5/10, Avg. Running Loss: 0.630428', Train Acc:67.30% Test Acc: 82.23%\n",
            "Epoch 5/9: 100% 131/131 [00:25<00:00,  5.16it/s, loss=0.79]\n",
            "[2025-12-07 11:50:29] Epoch 6/10, Avg. Running Loss: 0.632216', Train Acc:67.30% Test Acc: 82.23%\n",
            "[2025-12-07 11:50:29] No improvement in test accuracy for 5 consecutive epochs. Stopping early.\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "[2025-12-07 11:50:35] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90      2800\n",
            "           1       0.00      0.00      0.00       605\n",
            "\n",
            "    accuracy                           0.82      3405\n",
            "   macro avg       0.41      0.50      0.45      3405\n",
            "weighted avg       0.68      0.82      0.74      3405\n",
            "\n",
            "[2025-12-07 11:50:35] Confusion Matrix:\n",
            "[[2800    0]\n",
            " [ 605    0]]\n",
            "[2025-12-07 11:50:35] Saved confusion matrix to /content/drive/MyDrive/ViT_MoCo_Project/artifacts/confusion_matrix_20251207_115029.png\n",
            "[2025-12-07 11:50:35] MoCo backbone testing complete!\n",
            "[2025-12-07 11:50:35] MoCo backbone testing complete!!\n",
            "[2025-12-07 11:50:35] Saved testing stats to /content/drive/MyDrive/ViT_MoCo_Project/artifacts//test_stats.json\n"
          ]
        }
      ],
      "source": [
        "! python moco/test_moco_vit_hybrid.py \\\n",
        "    --root_dir \"$DATA_DEST_UNZIPPED\" \\\n",
        "    --artifact_root \"$ROOT_ARTIFACT_SAVE\" \\\n",
        "    --test_num_classes 2 \\\n",
        "    --linear_n_epochs 10 \\\n",
        "    --linear_train_csv_path \"$LINEAR_TRAIN_LABELS_CSV\" \\\n",
        "    --linear_test_csv_path \"$LINEAR_TEST_LABELS_CSV\" \\\n",
        "    --model_checkpoint \"vit_hybrid_moco_checkpoint_epoch_37.pth\" \\\n",
        "    --batch_size \"$batch_size\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bv-ag2zqGKLg"
      },
      "id": "bv-ag2zqGKLg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_patch_importance(model, dataloader, device, k=10):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import torch\n",
        "\n",
        "    # 1) Get one sample from loader\n",
        "    model.eval()\n",
        "    images, labels = next(iter(dataloader))\n",
        "    img = images[0].to(device)              # (3,224,224)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, patch_scores = model(img.unsqueeze(0))\n",
        "\n",
        "    patch_scores = patch_scores[0]          # (196,)\n",
        "\n",
        "    # 2) Prep score data\n",
        "    scores = patch_scores.detach().cpu().numpy()\n",
        "    topk_idx = np.argsort(scores)[-k:]      # top-K patch indices\n",
        "\n",
        "    # Convert indices  patch grid coords\n",
        "    coords = [(i // 14, i % 14) for i in topk_idx]\n",
        "\n",
        "    # 3) Convert image for drawing\n",
        "    img_np = img.cpu().permute(1,2,0).numpy()\n",
        "    img_np = (img_np * 255).astype(np.uint8)\n",
        "    img_draw = img_np.copy()\n",
        "\n",
        "    patch_size = 16   # for ViT-B/16\n",
        "\n",
        "    # 4) Draw red bounding boxes\n",
        "    for (r, c) in coords:\n",
        "        y1, x1 = r * patch_size, c * patch_size\n",
        "        y2, x2 = y1 + patch_size, x1 + patch_size\n",
        "        cv2.rectangle(img_draw, (x1, y1), (x2, y2), (255,0,0), 2)\n",
        "\n",
        "    # 5) Display result\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(img_draw)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Top {k} Highest-Scoring Patches (Red Boxes)\")\n",
        "    plt.show()\n",
        "\n",
        "    return img_draw, scores\n",
        "\n",
        "_ = visualize_patch_importance(trained_model, val_loader, device, k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "IW7vXDgyGKOX",
        "outputId": "60ceaa4d-efb0-4968-923d-42a726089802"
      },
      "id": "IW7vXDgyGKOX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trained_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-40031646.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_patch_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trained_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_patch_scores(image_tensor, scores):\n",
        "    # Converting image from tensor to numpy for OpenCV\n",
        "    img = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # Normalizing patch scores (so color map has meaningful scale)\n",
        "    s = scores.detach().cpu().numpy()\n",
        "    s = (s - s.min()) / (s.max() - s.min() + 1e-8)\n",
        "\n",
        "    # Reshaping to ViT patch grid (14x14 for ViT-B/16)\n",
        "    s = s.reshape(14, 14)\n",
        "\n",
        "    # Upscaling patch heatmap to full image resolution\n",
        "    s = cv2.resize(s, (224, 224))\n",
        "\n",
        "    # Generating heatmap overlay\n",
        "    heatmap = cv2.applyColorMap((s * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Combining heatmap with original image (weighted blend)\n",
        "    overlay = (0.5 * img + 0.5 * heatmap).astype(np.uint8)\n",
        "\n",
        "    # Displaying both images side-by-side\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Original Image\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Patch Score Heatmap (Rainbow)\")\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# === VISUALIZE PATCH SCORES ON ONE VALIDATION SAMPLE ===\n",
        "\n",
        "# 1. Rebuild validation loader exactly like in training\n",
        "_, val_loader = build_dataloaders()\n",
        "\n",
        "# 2. Get one batch\n",
        "images, labels = next(iter(val_loader))\n",
        "\n",
        "# 3. Pick first image\n",
        "img = images[0].to(device)\n",
        "\n",
        "# 4. Run model forward pass to get logits + patch_scores\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits, patch_scores = model(img.unsqueeze(0))\n",
        "\n",
        "# 5. IMPORTANT: remove batch dimension and move to CPU\n",
        "patch_scores = patch_scores[0]    # shape: (196,)\n",
        "img_vis = img.cpu()               # already in [0,1] because you did NOT normalize\n",
        "\n",
        "# 6. Visualize patch importance heatmap\n",
        "visualize_patch_scores(img_vis, patch_scores)\n"
      ],
      "metadata": {
        "id": "pXzSptrdGN51"
      },
      "id": "pXzSptrdGN51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "def visualize_patch_scores_clinical(image_tensor, scores):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import torch\n",
        "\n",
        "    # Convert image to uint8\n",
        "    img = image_tensor.permute(1,2,0).cpu().numpy()\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # Normalize scores\n",
        "    s = scores.detach().cpu().numpy()\n",
        "    s = (s - s.min()) / (s.max() - s.min() + 1e-8)\n",
        "\n",
        "    # 14x14  224x224 smooth upsample\n",
        "    heat = s.reshape(14, 14)\n",
        "    heat = cv2.resize(heat, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # Use perceptual colormap (inferno = clinically preferred)\n",
        "    cmap = cm.inferno\n",
        "    heat_color = (cmap(heat)[..., :3] * 255).astype(np.uint8)\n",
        "\n",
        "    # Blend with image\n",
        "    overlay = (0.6 * img + 0.4 * heat_color).astype(np.uint8)\n",
        "\n",
        "    # Display\n",
        "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
        "    ax[0].imshow(img)\n",
        "    ax[0].axis(\"off\")\n",
        "    ax[0].set_title(\"Original Image\")\n",
        "\n",
        "    ax[1].imshow(overlay)\n",
        "    ax[1].axis(\"off\")\n",
        "    ax[1].set_title(\"Patch Score Heatmap (Inferno)\")\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "visualize_patch_scores_clinical(img_vis, patch_scores)\n",
        "\n",
        "def visualize_patch_scores_clinical(image_tensor, scores):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import matplotlib.cm as cm\n",
        "    from matplotlib import gridspec\n",
        "\n",
        "    # --- Convert image to displayable uint8 ---\n",
        "    img = image_tensor.permute(1,2,0).cpu().numpy()\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # --- Normalize patch scores but keep true min/max for colorbar ---\n",
        "    s = scores.detach().cpu().numpy()\n",
        "    s_min, s_max = s.min(), s.max()\n",
        "    s_norm = (s - s_min) / (s_max - s_min + 1e-8)\n",
        "\n",
        "    # --- 14x14  224x224 heatmap ---\n",
        "    heat = s_norm.reshape(14, 14)\n",
        "    heat = cv2.resize(heat, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # --- Colorize ---\n",
        "    cmap = cm.inferno\n",
        "    heat_color = (cmap(heat)[..., :3] * 255).astype(np.uint8)\n",
        "\n",
        "    # --- Blend with original ---\n",
        "    overlay = (0.6 * img + 0.4 * heat_color).astype(np.uint8)\n",
        "\n",
        "    # --- Grid layout to prevent squeezing ---\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 0.05])\n",
        "\n",
        "    ax0 = plt.subplot(gs[0])\n",
        "    ax1 = plt.subplot(gs[1])\n",
        "    cax = plt.subplot(gs[2])  # dedicated colorbar axis\n",
        "\n",
        "    # Left: Original\n",
        "    ax0.imshow(img)\n",
        "    ax0.axis(\"off\")\n",
        "    ax0.set_title(\"Original Image\", fontsize=18)\n",
        "\n",
        "    # Right: Heatmap overlay\n",
        "    im = ax1.imshow(overlay)\n",
        "    ax1.axis(\"off\")\n",
        "    ax1.set_title(\"Patch Score Heatmap (Inferno)\", fontsize=18)\n",
        "\n",
        "    # Colorbar with true raw score scale\n",
        "    norm = plt.Normalize(vmin=0.0, vmax=1.0)\n",
        "    sm = cm.ScalarMappable(norm=norm, cmap=\"inferno\")\n",
        "    sm.set_array([])\n",
        "\n",
        "    cb = plt.colorbar(sm, cax=cax)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_patch_scores_clinical(img_vis, patch_scores)\n",
        "\n",
        "def visualize_patch_scores_clinical(image_tensor, scores):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import matplotlib.cm as cm\n",
        "    from matplotlib import gridspec\n",
        "\n",
        "    # --- Convert image to displayable uint8 ---\n",
        "    img = image_tensor.permute(1,2,0).cpu().numpy()\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # --- Normalize patch scores but keep true min/max for colorbar ---\n",
        "    s = scores.detach().cpu().numpy()\n",
        "    s_min, s_max = s.min(), s.max()\n",
        "    s_norm = (s - s_min) / (s_max - s_min + 1e-8)\n",
        "\n",
        "    # --- 14x14  224x224 heatmap ---\n",
        "    heat = s_norm.reshape(14, 14)\n",
        "    heat = cv2.resize(heat, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # --- Colorize ---\n",
        "    cmap = cm.jet\n",
        "    heat_color = (cmap(heat)[..., :3] * 255).astype(np.uint8)\n",
        "\n",
        "    # --- Blend with original ---\n",
        "    overlay = (0.6 * img + 0.4 * heat_color).astype(np.uint8)\n",
        "\n",
        "    # --- Grid layout to prevent squeezing ---\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 0.05])\n",
        "\n",
        "    ax0 = plt.subplot(gs[0])\n",
        "    ax1 = plt.subplot(gs[1])\n",
        "    cax = plt.subplot(gs[2])  # dedicated colorbar axis\n",
        "\n",
        "    # Left: Original\n",
        "    ax0.imshow(img)\n",
        "    ax0.axis(\"off\")\n",
        "    ax0.set_title(\"Original Image\", fontsize=18)\n",
        "\n",
        "    # Right: Heatmap overlay\n",
        "    im = ax1.imshow(overlay)\n",
        "    ax1.axis(\"off\")\n",
        "    ax1.set_title(\"Patch Score Heatmap\", fontsize=24)\n",
        "\n",
        "\n",
        "    # Colorbar with true raw score scale\n",
        "    norm = plt.Normalize(vmin=0.0, vmax=1.0)\n",
        "    sm = cm.ScalarMappable(norm=norm, cmap=\"jet\")\n",
        "    sm.set_array([])\n",
        "\n",
        "    cb = plt.colorbar(sm, cax=cax)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_patch_scores_clinical(img_vis, patch_scores)\n",
        "\n",
        "def visualize_patch_scores_clinical(image_tensor, scores):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import matplotlib.cm as cm\n",
        "    from matplotlib import gridspec\n",
        "\n",
        "    # Convert image to displayable uint8 ---\n",
        "    img = image_tensor.permute(1,2,0).cpu().numpy()\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # Normalize patch scores\n",
        "    s = scores.detach().cpu().numpy()\n",
        "    s_norm = (s - s.min()) / (s.max() - s.min() + 1e-8)\n",
        "\n",
        "    # 14x14  224x224 heatmap\n",
        "    heat = s_norm.reshape(14, 14)\n",
        "    heat = cv2.resize(heat, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # Colorize\n",
        "    cmap = cm.inferno\n",
        "    heat_color = (cmap(heat)[..., :3] * 255).astype(np.uint8)\n",
        "\n",
        "    # Blend with original\n",
        "    overlay = (0.6 * img + 0.4 * heat_color).astype(np.uint8)\n",
        "\n",
        "    # Grid layout with 2 main axes only\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1])\n",
        "\n",
        "    ax0 = plt.subplot(gs[0])\n",
        "    ax1 = plt.subplot(gs[1])\n",
        "\n",
        "    # Original\n",
        "    ax0.imshow(img)\n",
        "    ax0.axis(\"off\")\n",
        "    ax0.set_title(\"Original Image\", fontsize=20)\n",
        "\n",
        "    # Heatmap overlay\n",
        "    im = ax1.imshow(overlay)\n",
        "    ax1.axis(\"off\")\n",
        "    ax1.set_title(\"Patch Score Heatmap (Inferno)\", fontsize=20)\n",
        "\n",
        "    # Colorbar\n",
        "    norm = plt.Normalize(vmin=0.0, vmax=1.0)\n",
        "    sm = cm.ScalarMappable(norm=norm, cmap=\"inferno\")\n",
        "    sm.set_array([])\n",
        "\n",
        "    # Colorbar same height as heatmap ---\n",
        "    cb = fig.colorbar(sm, ax=ax1, fraction=0.046, pad=0.04)\n",
        "    cb.set_label(\"Normalized Patch Importance\", fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_patch_scores_clinical(img_vis, patch_scores)\n",
        "\n",
        "def visualize_all_patches(image_tensor, patch_scores):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import matplotlib.cm as cm\n",
        "\n",
        "    img = image_tensor.permute(1,2,0).cpu().numpy()\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # Normalize patch scores\n",
        "    s = patch_scores.detach().cpu().numpy()\n",
        "    s_norm = (s - s.min()) / (s.max() - s.min() + 1e-8)\n",
        "    grid = s_norm.reshape(14,14)\n",
        "\n",
        "    cmap = cm.inferno\n",
        "    patch_size = 16\n",
        "    img_draw = img.copy()\n",
        "\n",
        "    # DRAW BORDERS\n",
        "    for r in range(14):\n",
        "        for c in range(14):\n",
        "            score = grid[r,c]\n",
        "\n",
        "            rgb = np.array(cmap(score)[:3]) * 255\n",
        "            rgb = rgb.astype(np.uint8)\n",
        "            color = (int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
        "\n",
        "            y1, x1 = r * patch_size, c * patch_size\n",
        "            y2, x2 = y1 + patch_size, x1 + patch_size\n",
        "\n",
        "            cv2.rectangle(img_draw, (x1, y1), (x2, y2), color, 1)\n",
        "\n",
        "    # PLOT WITH COLORBAR\n",
        "    fig, ax = plt.subplots(figsize=(7,7))\n",
        "\n",
        "    im = ax.imshow(img_draw)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"All Patches (Score-Based Colored Borders)\", fontsize=16)\n",
        "\n",
        "    # Create colorbar using normalized scale (01)\n",
        "    norm = plt.Normalize(vmin=0.0, vmax=1.0)\n",
        "    sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
        "    sm.set_array([])\n",
        "\n",
        "    # add colorbar matching height of the image\n",
        "    cbar = fig.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return img_draw\n",
        "\n",
        "visualize_all_patches(img_vis, patch_scores)"
      ],
      "metadata": {
        "id": "h1XfUTYZGN8p"
      },
      "id": "h1XfUTYZGN8p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-aFpowqGGN-6"
      },
      "id": "-aFpowqGGN-6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}