[2025-12-02 02:37:28] Starting MoCo backbone testing...
[2025-12-02 02:37:29] Loading pretrained MoCo model from /content/drive/MyDrive/Colab Notebooks/7_Py_DL/FP/artifacts/vit_hybrid_moco_encoder.pth...
[2025-12-02 02:37:35] Detected 'model_state' in checkpoint. Extracting encoder_q weights.
[2025-12-02 02:37:35] Loaded pretrained encoder. missing keys: ['queue', 'queue_ptr', 'encoder_q.patch_embed.proj.0.weight', 'encoder_q.patch_embed.proj.0.bias', 'encoder_q.patch_embed.proj.2.weight', 'encoder_q.patch_embed.proj.2.bias', 'encoder_q.transformer.blocks.layers.0.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.0.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.0.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.0.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.0.linear1.weight', 'encoder_q.transformer.blocks.layers.0.linear1.bias', 'encoder_q.transformer.blocks.layers.0.linear2.weight', 'encoder_q.transformer.blocks.layers.0.linear2.bias', 'encoder_q.transformer.blocks.layers.0.norm1.weight', 'encoder_q.transformer.blocks.layers.0.norm1.bias', 'encoder_q.transformer.blocks.layers.0.norm2.weight', 'encoder_q.transformer.blocks.layers.0.norm2.bias', 'encoder_q.transformer.blocks.layers.1.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.1.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.1.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.1.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.1.linear1.weight', 'encoder_q.transformer.blocks.layers.1.linear1.bias', 'encoder_q.transformer.blocks.layers.1.linear2.weight', 'encoder_q.transformer.blocks.layers.1.linear2.bias', 'encoder_q.transformer.blocks.layers.1.norm1.weight', 'encoder_q.transformer.blocks.layers.1.norm1.bias', 'encoder_q.transformer.blocks.layers.1.norm2.weight', 'encoder_q.transformer.blocks.layers.1.norm2.bias', 'encoder_q.transformer.blocks.layers.2.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.2.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.2.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.2.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.2.linear1.weight', 'encoder_q.transformer.blocks.layers.2.linear1.bias', 'encoder_q.transformer.blocks.layers.2.linear2.weight', 'encoder_q.transformer.blocks.layers.2.linear2.bias', 'encoder_q.transformer.blocks.layers.2.norm1.weight', 'encoder_q.transformer.blocks.layers.2.norm1.bias', 'encoder_q.transformer.blocks.layers.2.norm2.weight', 'encoder_q.transformer.blocks.layers.2.norm2.bias', 'encoder_q.transformer.blocks.layers.3.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.3.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.3.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.3.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.3.linear1.weight', 'encoder_q.transformer.blocks.layers.3.linear1.bias', 'encoder_q.transformer.blocks.layers.3.linear2.weight', 'encoder_q.transformer.blocks.layers.3.linear2.bias', 'encoder_q.transformer.blocks.layers.3.norm1.weight', 'encoder_q.transformer.blocks.layers.3.norm1.bias', 'encoder_q.transformer.blocks.layers.3.norm2.weight', 'encoder_q.transformer.blocks.layers.3.norm2.bias', 'encoder_q.transformer.blocks.layers.4.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.4.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.4.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.4.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.4.linear1.weight', 'encoder_q.transformer.blocks.layers.4.linear1.bias', 'encoder_q.transformer.blocks.layers.4.linear2.weight', 'encoder_q.transformer.blocks.layers.4.linear2.bias', 'encoder_q.transformer.blocks.layers.4.norm1.weight', 'encoder_q.transformer.blocks.layers.4.norm1.bias', 'encoder_q.transformer.blocks.layers.4.norm2.weight', 'encoder_q.transformer.blocks.layers.4.norm2.bias', 'encoder_q.transformer.blocks.layers.5.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.5.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.5.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.5.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.5.linear1.weight', 'encoder_q.transformer.blocks.layers.5.linear1.bias', 'encoder_q.transformer.blocks.layers.5.linear2.weight', 'encoder_q.transformer.blocks.layers.5.linear2.bias', 'encoder_q.transformer.blocks.layers.5.norm1.weight', 'encoder_q.transformer.blocks.layers.5.norm1.bias', 'encoder_q.transformer.blocks.layers.5.norm2.weight', 'encoder_q.transformer.blocks.layers.5.norm2.bias', 'encoder_q.transformer.blocks.layers.6.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.6.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.6.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.6.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.6.linear1.weight', 'encoder_q.transformer.blocks.layers.6.linear1.bias', 'encoder_q.transformer.blocks.layers.6.linear2.weight', 'encoder_q.transformer.blocks.layers.6.linear2.bias', 'encoder_q.transformer.blocks.layers.6.norm1.weight', 'encoder_q.transformer.blocks.layers.6.norm1.bias', 'encoder_q.transformer.blocks.layers.6.norm2.weight', 'encoder_q.transformer.blocks.layers.6.norm2.bias', 'encoder_q.transformer.blocks.layers.7.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.7.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.7.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.7.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.7.linear1.weight', 'encoder_q.transformer.blocks.layers.7.linear1.bias', 'encoder_q.transformer.blocks.layers.7.linear2.weight', 'encoder_q.transformer.blocks.layers.7.linear2.bias', 'encoder_q.transformer.blocks.layers.7.norm1.weight', 'encoder_q.transformer.blocks.layers.7.norm1.bias', 'encoder_q.transformer.blocks.layers.7.norm2.weight', 'encoder_q.transformer.blocks.layers.7.norm2.bias', 'encoder_q.transformer.blocks.layers.8.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.8.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.8.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.8.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.8.linear1.weight', 'encoder_q.transformer.blocks.layers.8.linear1.bias', 'encoder_q.transformer.blocks.layers.8.linear2.weight', 'encoder_q.transformer.blocks.layers.8.linear2.bias', 'encoder_q.transformer.blocks.layers.8.norm1.weight', 'encoder_q.transformer.blocks.layers.8.norm1.bias', 'encoder_q.transformer.blocks.layers.8.norm2.weight', 'encoder_q.transformer.blocks.layers.8.norm2.bias', 'encoder_q.transformer.blocks.layers.9.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.9.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.9.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.9.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.9.linear1.weight', 'encoder_q.transformer.blocks.layers.9.linear1.bias', 'encoder_q.transformer.blocks.layers.9.linear2.weight', 'encoder_q.transformer.blocks.layers.9.linear2.bias', 'encoder_q.transformer.blocks.layers.9.norm1.weight', 'encoder_q.transformer.blocks.layers.9.norm1.bias', 'encoder_q.transformer.blocks.layers.9.norm2.weight', 'encoder_q.transformer.blocks.layers.9.norm2.bias', 'encoder_q.transformer.blocks.layers.10.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.10.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.10.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.10.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.10.linear1.weight', 'encoder_q.transformer.blocks.layers.10.linear1.bias', 'encoder_q.transformer.blocks.layers.10.linear2.weight', 'encoder_q.transformer.blocks.layers.10.linear2.bias', 'encoder_q.transformer.blocks.layers.10.norm1.weight', 'encoder_q.transformer.blocks.layers.10.norm1.bias', 'encoder_q.transformer.blocks.layers.10.norm2.weight', 'encoder_q.transformer.blocks.layers.10.norm2.bias', 'encoder_q.transformer.blocks.layers.11.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.11.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.11.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.11.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.11.linear1.weight', 'encoder_q.transformer.blocks.layers.11.linear1.bias', 'encoder_q.transformer.blocks.layers.11.linear2.weight', 'encoder_q.transformer.blocks.layers.11.linear2.bias', 'encoder_q.transformer.blocks.layers.11.norm1.weight', 'encoder_q.transformer.blocks.layers.11.norm1.bias', 'encoder_q.transformer.blocks.layers.11.norm2.weight', 'encoder_q.transformer.blocks.layers.11.norm2.bias', 'encoder_k.patch_embed.proj.0.weight', 'encoder_k.patch_embed.proj.0.bias', 'encoder_k.patch_embed.proj.2.weight', 'encoder_k.patch_embed.proj.2.bias', 'encoder_k.transformer.blocks.layers.0.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.0.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.0.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.0.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.0.linear1.weight', 'encoder_k.transformer.blocks.layers.0.linear1.bias', 'encoder_k.transformer.blocks.layers.0.linear2.weight', 'encoder_k.transformer.blocks.layers.0.linear2.bias', 'encoder_k.transformer.blocks.layers.0.norm1.weight', 'encoder_k.transformer.blocks.layers.0.norm1.bias', 'encoder_k.transformer.blocks.layers.0.norm2.weight', 'encoder_k.transformer.blocks.layers.0.norm2.bias', 'encoder_k.transformer.blocks.layers.1.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.1.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.1.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.1.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.1.linear1.weight', 'encoder_k.transformer.blocks.layers.1.linear1.bias', 'encoder_k.transformer.blocks.layers.1.linear2.weight', 'encoder_k.transformer.blocks.layers.1.linear2.bias', 'encoder_k.transformer.blocks.layers.1.norm1.weight', 'encoder_k.transformer.blocks.layers.1.norm1.bias', 'encoder_k.transformer.blocks.layers.1.norm2.weight', 'encoder_k.transformer.blocks.layers.1.norm2.bias', 'encoder_k.transformer.blocks.layers.2.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.2.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.2.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.2.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.2.linear1.weight', 'encoder_k.transformer.blocks.layers.2.linear1.bias', 'encoder_k.transformer.blocks.layers.2.linear2.weight', 'encoder_k.transformer.blocks.layers.2.linear2.bias', 'encoder_k.transformer.blocks.layers.2.norm1.weight', 'encoder_k.transformer.blocks.layers.2.norm1.bias', 'encoder_k.transformer.blocks.layers.2.norm2.weight', 'encoder_k.transformer.blocks.layers.2.norm2.bias', 'encoder_k.transformer.blocks.layers.3.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.3.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.3.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.3.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.3.linear1.weight', 'encoder_k.transformer.blocks.layers.3.linear1.bias', 'encoder_k.transformer.blocks.layers.3.linear2.weight', 'encoder_k.transformer.blocks.layers.3.linear2.bias', 'encoder_k.transformer.blocks.layers.3.norm1.weight', 'encoder_k.transformer.blocks.layers.3.norm1.bias', 'encoder_k.transformer.blocks.layers.3.norm2.weight', 'encoder_k.transformer.blocks.layers.3.norm2.bias', 'encoder_k.transformer.blocks.layers.4.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.4.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.4.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.4.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.4.linear1.weight', 'encoder_k.transformer.blocks.layers.4.linear1.bias', 'encoder_k.transformer.blocks.layers.4.linear2.weight', 'encoder_k.transformer.blocks.layers.4.linear2.bias', 'encoder_k.transformer.blocks.layers.4.norm1.weight', 'encoder_k.transformer.blocks.layers.4.norm1.bias', 'encoder_k.transformer.blocks.layers.4.norm2.weight', 'encoder_k.transformer.blocks.layers.4.norm2.bias', 'encoder_k.transformer.blocks.layers.5.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.5.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.5.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.5.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.5.linear1.weight', 'encoder_k.transformer.blocks.layers.5.linear1.bias', 'encoder_k.transformer.blocks.layers.5.linear2.weight', 'encoder_k.transformer.blocks.layers.5.linear2.bias', 'encoder_k.transformer.blocks.layers.5.norm1.weight', 'encoder_k.transformer.blocks.layers.5.norm1.bias', 'encoder_k.transformer.blocks.layers.5.norm2.weight', 'encoder_k.transformer.blocks.layers.5.norm2.bias', 'encoder_k.transformer.blocks.layers.6.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.6.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.6.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.6.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.6.linear1.weight', 'encoder_k.transformer.blocks.layers.6.linear1.bias', 'encoder_k.transformer.blocks.layers.6.linear2.weight', 'encoder_k.transformer.blocks.layers.6.linear2.bias', 'encoder_k.transformer.blocks.layers.6.norm1.weight', 'encoder_k.transformer.blocks.layers.6.norm1.bias', 'encoder_k.transformer.blocks.layers.6.norm2.weight', 'encoder_k.transformer.blocks.layers.6.norm2.bias', 'encoder_k.transformer.blocks.layers.7.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.7.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.7.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.7.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.7.linear1.weight', 'encoder_k.transformer.blocks.layers.7.linear1.bias', 'encoder_k.transformer.blocks.layers.7.linear2.weight', 'encoder_k.transformer.blocks.layers.7.linear2.bias', 'encoder_k.transformer.blocks.layers.7.norm1.weight', 'encoder_k.transformer.blocks.layers.7.norm1.bias', 'encoder_k.transformer.blocks.layers.7.norm2.weight', 'encoder_k.transformer.blocks.layers.7.norm2.bias', 'encoder_k.transformer.blocks.layers.8.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.8.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.8.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.8.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.8.linear1.weight', 'encoder_k.transformer.blocks.layers.8.linear1.bias', 'encoder_k.transformer.blocks.layers.8.linear2.weight', 'encoder_k.transformer.blocks.layers.8.linear2.bias', 'encoder_k.transformer.blocks.layers.8.norm1.weight', 'encoder_k.transformer.blocks.layers.8.norm1.bias', 'encoder_k.transformer.blocks.layers.8.norm2.weight', 'encoder_k.transformer.blocks.layers.8.norm2.bias', 'encoder_k.transformer.blocks.layers.9.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.9.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.9.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.9.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.9.linear1.weight', 'encoder_k.transformer.blocks.layers.9.linear1.bias', 'encoder_k.transformer.blocks.layers.9.linear2.weight', 'encoder_k.transformer.blocks.layers.9.linear2.bias', 'encoder_k.transformer.blocks.layers.9.norm1.weight', 'encoder_k.transformer.blocks.layers.9.norm1.bias', 'encoder_k.transformer.blocks.layers.9.norm2.weight', 'encoder_k.transformer.blocks.layers.9.norm2.bias', 'encoder_k.transformer.blocks.layers.10.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.10.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.10.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.10.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.10.linear1.weight', 'encoder_k.transformer.blocks.layers.10.linear1.bias', 'encoder_k.transformer.blocks.layers.10.linear2.weight', 'encoder_k.transformer.blocks.layers.10.linear2.bias', 'encoder_k.transformer.blocks.layers.10.norm1.weight', 'encoder_k.transformer.blocks.layers.10.norm1.bias', 'encoder_k.transformer.blocks.layers.10.norm2.weight', 'encoder_k.transformer.blocks.layers.10.norm2.bias', 'encoder_k.transformer.blocks.layers.11.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.11.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.11.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.11.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.11.linear1.weight', 'encoder_k.transformer.blocks.layers.11.linear1.bias', 'encoder_k.transformer.blocks.layers.11.linear2.weight', 'encoder_k.transformer.blocks.layers.11.linear2.bias', 'encoder_k.transformer.blocks.layers.11.norm1.weight', 'encoder_k.transformer.blocks.layers.11.norm1.bias', 'encoder_k.transformer.blocks.layers.11.norm2.weight', 'encoder_k.transformer.blocks.layers.11.norm2.bias', 'encoder_k_proj.0.weight', 'encoder_k_proj.0.bias', 'encoder_k_proj.2.weight', 'encoder_k_proj.2.bias'], unexpected: ['patch_embed.proj.0.weight', 'patch_embed.proj.0.bias', 'patch_embed.proj.2.weight', 'patch_embed.proj.2.bias', 'transformer.blocks.layers.0.self_attn.in_proj_weight', 'transformer.blocks.layers.0.self_attn.in_proj_bias', 'transformer.blocks.layers.0.self_attn.out_proj.weight', 'transformer.blocks.layers.0.self_attn.out_proj.bias', 'transformer.blocks.layers.0.linear1.weight', 'transformer.blocks.layers.0.linear1.bias', 'transformer.blocks.layers.0.linear2.weight', 'transformer.blocks.layers.0.linear2.bias', 'transformer.blocks.layers.0.norm1.weight', 'transformer.blocks.layers.0.norm1.bias', 'transformer.blocks.layers.0.norm2.weight', 'transformer.blocks.layers.0.norm2.bias', 'transformer.blocks.layers.1.self_attn.in_proj_weight', 'transformer.blocks.layers.1.self_attn.in_proj_bias', 'transformer.blocks.layers.1.self_attn.out_proj.weight', 'transformer.blocks.layers.1.self_attn.out_proj.bias', 'transformer.blocks.layers.1.linear1.weight', 'transformer.blocks.layers.1.linear1.bias', 'transformer.blocks.layers.1.linear2.weight', 'transformer.blocks.layers.1.linear2.bias', 'transformer.blocks.layers.1.norm1.weight', 'transformer.blocks.layers.1.norm1.bias', 'transformer.blocks.layers.1.norm2.weight', 'transformer.blocks.layers.1.norm2.bias', 'transformer.blocks.layers.2.self_attn.in_proj_weight', 'transformer.blocks.layers.2.self_attn.in_proj_bias', 'transformer.blocks.layers.2.self_attn.out_proj.weight', 'transformer.blocks.layers.2.self_attn.out_proj.bias', 'transformer.blocks.layers.2.linear1.weight', 'transformer.blocks.layers.2.linear1.bias', 'transformer.blocks.layers.2.linear2.weight', 'transformer.blocks.layers.2.linear2.bias', 'transformer.blocks.layers.2.norm1.weight', 'transformer.blocks.layers.2.norm1.bias', 'transformer.blocks.layers.2.norm2.weight', 'transformer.blocks.layers.2.norm2.bias', 'transformer.blocks.layers.3.self_attn.in_proj_weight', 'transformer.blocks.layers.3.self_attn.in_proj_bias', 'transformer.blocks.layers.3.self_attn.out_proj.weight', 'transformer.blocks.layers.3.self_attn.out_proj.bias', 'transformer.blocks.layers.3.linear1.weight', 'transformer.blocks.layers.3.linear1.bias', 'transformer.blocks.layers.3.linear2.weight', 'transformer.blocks.layers.3.linear2.bias', 'transformer.blocks.layers.3.norm1.weight', 'transformer.blocks.layers.3.norm1.bias', 'transformer.blocks.layers.3.norm2.weight', 'transformer.blocks.layers.3.norm2.bias', 'transformer.blocks.layers.4.self_attn.in_proj_weight', 'transformer.blocks.layers.4.self_attn.in_proj_bias', 'transformer.blocks.layers.4.self_attn.out_proj.weight', 'transformer.blocks.layers.4.self_attn.out_proj.bias', 'transformer.blocks.layers.4.linear1.weight', 'transformer.blocks.layers.4.linear1.bias', 'transformer.blocks.layers.4.linear2.weight', 'transformer.blocks.layers.4.linear2.bias', 'transformer.blocks.layers.4.norm1.weight', 'transformer.blocks.layers.4.norm1.bias', 'transformer.blocks.layers.4.norm2.weight', 'transformer.blocks.layers.4.norm2.bias', 'transformer.blocks.layers.5.self_attn.in_proj_weight', 'transformer.blocks.layers.5.self_attn.in_proj_bias', 'transformer.blocks.layers.5.self_attn.out_proj.weight', 'transformer.blocks.layers.5.self_attn.out_proj.bias', 'transformer.blocks.layers.5.linear1.weight', 'transformer.blocks.layers.5.linear1.bias', 'transformer.blocks.layers.5.linear2.weight', 'transformer.blocks.layers.5.linear2.bias', 'transformer.blocks.layers.5.norm1.weight', 'transformer.blocks.layers.5.norm1.bias', 'transformer.blocks.layers.5.norm2.weight', 'transformer.blocks.layers.5.norm2.bias', 'transformer.blocks.layers.6.self_attn.in_proj_weight', 'transformer.blocks.layers.6.self_attn.in_proj_bias', 'transformer.blocks.layers.6.self_attn.out_proj.weight', 'transformer.blocks.layers.6.self_attn.out_proj.bias', 'transformer.blocks.layers.6.linear1.weight', 'transformer.blocks.layers.6.linear1.bias', 'transformer.blocks.layers.6.linear2.weight', 'transformer.blocks.layers.6.linear2.bias', 'transformer.blocks.layers.6.norm1.weight', 'transformer.blocks.layers.6.norm1.bias', 'transformer.blocks.layers.6.norm2.weight', 'transformer.blocks.layers.6.norm2.bias', 'transformer.blocks.layers.7.self_attn.in_proj_weight', 'transformer.blocks.layers.7.self_attn.in_proj_bias', 'transformer.blocks.layers.7.self_attn.out_proj.weight', 'transformer.blocks.layers.7.self_attn.out_proj.bias', 'transformer.blocks.layers.7.linear1.weight', 'transformer.blocks.layers.7.linear1.bias', 'transformer.blocks.layers.7.linear2.weight', 'transformer.blocks.layers.7.linear2.bias', 'transformer.blocks.layers.7.norm1.weight', 'transformer.blocks.layers.7.norm1.bias', 'transformer.blocks.layers.7.norm2.weight', 'transformer.blocks.layers.7.norm2.bias', 'transformer.blocks.layers.8.self_attn.in_proj_weight', 'transformer.blocks.layers.8.self_attn.in_proj_bias', 'transformer.blocks.layers.8.self_attn.out_proj.weight', 'transformer.blocks.layers.8.self_attn.out_proj.bias', 'transformer.blocks.layers.8.linear1.weight', 'transformer.blocks.layers.8.linear1.bias', 'transformer.blocks.layers.8.linear2.weight', 'transformer.blocks.layers.8.linear2.bias', 'transformer.blocks.layers.8.norm1.weight', 'transformer.blocks.layers.8.norm1.bias', 'transformer.blocks.layers.8.norm2.weight', 'transformer.blocks.layers.8.norm2.bias', 'transformer.blocks.layers.9.self_attn.in_proj_weight', 'transformer.blocks.layers.9.self_attn.in_proj_bias', 'transformer.blocks.layers.9.self_attn.out_proj.weight', 'transformer.blocks.layers.9.self_attn.out_proj.bias', 'transformer.blocks.layers.9.linear1.weight', 'transformer.blocks.layers.9.linear1.bias', 'transformer.blocks.layers.9.linear2.weight', 'transformer.blocks.layers.9.linear2.bias', 'transformer.blocks.layers.9.norm1.weight', 'transformer.blocks.layers.9.norm1.bias', 'transformer.blocks.layers.9.norm2.weight', 'transformer.blocks.layers.9.norm2.bias', 'transformer.blocks.layers.10.self_attn.in_proj_weight', 'transformer.blocks.layers.10.self_attn.in_proj_bias', 'transformer.blocks.layers.10.self_attn.out_proj.weight', 'transformer.blocks.layers.10.self_attn.out_proj.bias', 'transformer.blocks.layers.10.linear1.weight', 'transformer.blocks.layers.10.linear1.bias', 'transformer.blocks.layers.10.linear2.weight', 'transformer.blocks.layers.10.linear2.bias', 'transformer.blocks.layers.10.norm1.weight', 'transformer.blocks.layers.10.norm1.bias', 'transformer.blocks.layers.10.norm2.weight', 'transformer.blocks.layers.10.norm2.bias', 'transformer.blocks.layers.11.self_attn.in_proj_weight', 'transformer.blocks.layers.11.self_attn.in_proj_bias', 'transformer.blocks.layers.11.self_attn.out_proj.weight', 'transformer.blocks.layers.11.self_attn.out_proj.bias', 'transformer.blocks.layers.11.linear1.weight', 'transformer.blocks.layers.11.linear1.bias', 'transformer.blocks.layers.11.linear2.weight', 'transformer.blocks.layers.11.linear2.bias', 'transformer.blocks.layers.11.norm1.weight', 'transformer.blocks.layers.11.norm1.bias', 'transformer.blocks.layers.11.norm2.weight', 'transformer.blocks.layers.11.norm2.bias']
[2025-12-02 02:37:37] Starting MoCo backbone testing...
[2025-12-02 02:37:37] Model Keys: odict_keys(['queue', 'queue_ptr', 'encoder_q.patch_embed.proj.0.weight', 'encoder_q.patch_embed.proj.0.bias', 'encoder_q.patch_embed.proj.2.weight', 'encoder_q.patch_embed.proj.2.bias', 'encoder_q.transformer.blocks.layers.0.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.0.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.0.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.0.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.0.linear1.weight', 'encoder_q.transformer.blocks.layers.0.linear1.bias', 'encoder_q.transformer.blocks.layers.0.linear2.weight', 'encoder_q.transformer.blocks.layers.0.linear2.bias', 'encoder_q.transformer.blocks.layers.0.norm1.weight', 'encoder_q.transformer.blocks.layers.0.norm1.bias', 'encoder_q.transformer.blocks.layers.0.norm2.weight', 'encoder_q.transformer.blocks.layers.0.norm2.bias', 'encoder_q.transformer.blocks.layers.1.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.1.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.1.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.1.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.1.linear1.weight', 'encoder_q.transformer.blocks.layers.1.linear1.bias', 'encoder_q.transformer.blocks.layers.1.linear2.weight', 'encoder_q.transformer.blocks.layers.1.linear2.bias', 'encoder_q.transformer.blocks.layers.1.norm1.weight', 'encoder_q.transformer.blocks.layers.1.norm1.bias', 'encoder_q.transformer.blocks.layers.1.norm2.weight', 'encoder_q.transformer.blocks.layers.1.norm2.bias', 'encoder_q.transformer.blocks.layers.2.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.2.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.2.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.2.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.2.linear1.weight', 'encoder_q.transformer.blocks.layers.2.linear1.bias', 'encoder_q.transformer.blocks.layers.2.linear2.weight', 'encoder_q.transformer.blocks.layers.2.linear2.bias', 'encoder_q.transformer.blocks.layers.2.norm1.weight', 'encoder_q.transformer.blocks.layers.2.norm1.bias', 'encoder_q.transformer.blocks.layers.2.norm2.weight', 'encoder_q.transformer.blocks.layers.2.norm2.bias', 'encoder_q.transformer.blocks.layers.3.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.3.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.3.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.3.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.3.linear1.weight', 'encoder_q.transformer.blocks.layers.3.linear1.bias', 'encoder_q.transformer.blocks.layers.3.linear2.weight', 'encoder_q.transformer.blocks.layers.3.linear2.bias', 'encoder_q.transformer.blocks.layers.3.norm1.weight', 'encoder_q.transformer.blocks.layers.3.norm1.bias', 'encoder_q.transformer.blocks.layers.3.norm2.weight', 'encoder_q.transformer.blocks.layers.3.norm2.bias', 'encoder_q.transformer.blocks.layers.4.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.4.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.4.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.4.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.4.linear1.weight', 'encoder_q.transformer.blocks.layers.4.linear1.bias', 'encoder_q.transformer.blocks.layers.4.linear2.weight', 'encoder_q.transformer.blocks.layers.4.linear2.bias', 'encoder_q.transformer.blocks.layers.4.norm1.weight', 'encoder_q.transformer.blocks.layers.4.norm1.bias', 'encoder_q.transformer.blocks.layers.4.norm2.weight', 'encoder_q.transformer.blocks.layers.4.norm2.bias', 'encoder_q.transformer.blocks.layers.5.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.5.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.5.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.5.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.5.linear1.weight', 'encoder_q.transformer.blocks.layers.5.linear1.bias', 'encoder_q.transformer.blocks.layers.5.linear2.weight', 'encoder_q.transformer.blocks.layers.5.linear2.bias', 'encoder_q.transformer.blocks.layers.5.norm1.weight', 'encoder_q.transformer.blocks.layers.5.norm1.bias', 'encoder_q.transformer.blocks.layers.5.norm2.weight', 'encoder_q.transformer.blocks.layers.5.norm2.bias', 'encoder_q.transformer.blocks.layers.6.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.6.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.6.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.6.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.6.linear1.weight', 'encoder_q.transformer.blocks.layers.6.linear1.bias', 'encoder_q.transformer.blocks.layers.6.linear2.weight', 'encoder_q.transformer.blocks.layers.6.linear2.bias', 'encoder_q.transformer.blocks.layers.6.norm1.weight', 'encoder_q.transformer.blocks.layers.6.norm1.bias', 'encoder_q.transformer.blocks.layers.6.norm2.weight', 'encoder_q.transformer.blocks.layers.6.norm2.bias', 'encoder_q.transformer.blocks.layers.7.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.7.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.7.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.7.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.7.linear1.weight', 'encoder_q.transformer.blocks.layers.7.linear1.bias', 'encoder_q.transformer.blocks.layers.7.linear2.weight', 'encoder_q.transformer.blocks.layers.7.linear2.bias', 'encoder_q.transformer.blocks.layers.7.norm1.weight', 'encoder_q.transformer.blocks.layers.7.norm1.bias', 'encoder_q.transformer.blocks.layers.7.norm2.weight', 'encoder_q.transformer.blocks.layers.7.norm2.bias', 'encoder_q.transformer.blocks.layers.8.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.8.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.8.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.8.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.8.linear1.weight', 'encoder_q.transformer.blocks.layers.8.linear1.bias', 'encoder_q.transformer.blocks.layers.8.linear2.weight', 'encoder_q.transformer.blocks.layers.8.linear2.bias', 'encoder_q.transformer.blocks.layers.8.norm1.weight', 'encoder_q.transformer.blocks.layers.8.norm1.bias', 'encoder_q.transformer.blocks.layers.8.norm2.weight', 'encoder_q.transformer.blocks.layers.8.norm2.bias', 'encoder_q.transformer.blocks.layers.9.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.9.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.9.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.9.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.9.linear1.weight', 'encoder_q.transformer.blocks.layers.9.linear1.bias', 'encoder_q.transformer.blocks.layers.9.linear2.weight', 'encoder_q.transformer.blocks.layers.9.linear2.bias', 'encoder_q.transformer.blocks.layers.9.norm1.weight', 'encoder_q.transformer.blocks.layers.9.norm1.bias', 'encoder_q.transformer.blocks.layers.9.norm2.weight', 'encoder_q.transformer.blocks.layers.9.norm2.bias', 'encoder_q.transformer.blocks.layers.10.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.10.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.10.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.10.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.10.linear1.weight', 'encoder_q.transformer.blocks.layers.10.linear1.bias', 'encoder_q.transformer.blocks.layers.10.linear2.weight', 'encoder_q.transformer.blocks.layers.10.linear2.bias', 'encoder_q.transformer.blocks.layers.10.norm1.weight', 'encoder_q.transformer.blocks.layers.10.norm1.bias', 'encoder_q.transformer.blocks.layers.10.norm2.weight', 'encoder_q.transformer.blocks.layers.10.norm2.bias', 'encoder_q.transformer.blocks.layers.11.self_attn.in_proj_weight', 'encoder_q.transformer.blocks.layers.11.self_attn.in_proj_bias', 'encoder_q.transformer.blocks.layers.11.self_attn.out_proj.weight', 'encoder_q.transformer.blocks.layers.11.self_attn.out_proj.bias', 'encoder_q.transformer.blocks.layers.11.linear1.weight', 'encoder_q.transformer.blocks.layers.11.linear1.bias', 'encoder_q.transformer.blocks.layers.11.linear2.weight', 'encoder_q.transformer.blocks.layers.11.linear2.bias', 'encoder_q.transformer.blocks.layers.11.norm1.weight', 'encoder_q.transformer.blocks.layers.11.norm1.bias', 'encoder_q.transformer.blocks.layers.11.norm2.weight', 'encoder_q.transformer.blocks.layers.11.norm2.bias', 'encoder_q_proj.0.weight', 'encoder_q_proj.0.bias', 'encoder_q_proj.2.weight', 'encoder_q_proj.2.bias', 'encoder_k.patch_embed.proj.0.weight', 'encoder_k.patch_embed.proj.0.bias', 'encoder_k.patch_embed.proj.2.weight', 'encoder_k.patch_embed.proj.2.bias', 'encoder_k.transformer.blocks.layers.0.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.0.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.0.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.0.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.0.linear1.weight', 'encoder_k.transformer.blocks.layers.0.linear1.bias', 'encoder_k.transformer.blocks.layers.0.linear2.weight', 'encoder_k.transformer.blocks.layers.0.linear2.bias', 'encoder_k.transformer.blocks.layers.0.norm1.weight', 'encoder_k.transformer.blocks.layers.0.norm1.bias', 'encoder_k.transformer.blocks.layers.0.norm2.weight', 'encoder_k.transformer.blocks.layers.0.norm2.bias', 'encoder_k.transformer.blocks.layers.1.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.1.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.1.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.1.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.1.linear1.weight', 'encoder_k.transformer.blocks.layers.1.linear1.bias', 'encoder_k.transformer.blocks.layers.1.linear2.weight', 'encoder_k.transformer.blocks.layers.1.linear2.bias', 'encoder_k.transformer.blocks.layers.1.norm1.weight', 'encoder_k.transformer.blocks.layers.1.norm1.bias', 'encoder_k.transformer.blocks.layers.1.norm2.weight', 'encoder_k.transformer.blocks.layers.1.norm2.bias', 'encoder_k.transformer.blocks.layers.2.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.2.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.2.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.2.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.2.linear1.weight', 'encoder_k.transformer.blocks.layers.2.linear1.bias', 'encoder_k.transformer.blocks.layers.2.linear2.weight', 'encoder_k.transformer.blocks.layers.2.linear2.bias', 'encoder_k.transformer.blocks.layers.2.norm1.weight', 'encoder_k.transformer.blocks.layers.2.norm1.bias', 'encoder_k.transformer.blocks.layers.2.norm2.weight', 'encoder_k.transformer.blocks.layers.2.norm2.bias', 'encoder_k.transformer.blocks.layers.3.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.3.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.3.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.3.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.3.linear1.weight', 'encoder_k.transformer.blocks.layers.3.linear1.bias', 'encoder_k.transformer.blocks.layers.3.linear2.weight', 'encoder_k.transformer.blocks.layers.3.linear2.bias', 'encoder_k.transformer.blocks.layers.3.norm1.weight', 'encoder_k.transformer.blocks.layers.3.norm1.bias', 'encoder_k.transformer.blocks.layers.3.norm2.weight', 'encoder_k.transformer.blocks.layers.3.norm2.bias', 'encoder_k.transformer.blocks.layers.4.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.4.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.4.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.4.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.4.linear1.weight', 'encoder_k.transformer.blocks.layers.4.linear1.bias', 'encoder_k.transformer.blocks.layers.4.linear2.weight', 'encoder_k.transformer.blocks.layers.4.linear2.bias', 'encoder_k.transformer.blocks.layers.4.norm1.weight', 'encoder_k.transformer.blocks.layers.4.norm1.bias', 'encoder_k.transformer.blocks.layers.4.norm2.weight', 'encoder_k.transformer.blocks.layers.4.norm2.bias', 'encoder_k.transformer.blocks.layers.5.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.5.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.5.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.5.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.5.linear1.weight', 'encoder_k.transformer.blocks.layers.5.linear1.bias', 'encoder_k.transformer.blocks.layers.5.linear2.weight', 'encoder_k.transformer.blocks.layers.5.linear2.bias', 'encoder_k.transformer.blocks.layers.5.norm1.weight', 'encoder_k.transformer.blocks.layers.5.norm1.bias', 'encoder_k.transformer.blocks.layers.5.norm2.weight', 'encoder_k.transformer.blocks.layers.5.norm2.bias', 'encoder_k.transformer.blocks.layers.6.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.6.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.6.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.6.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.6.linear1.weight', 'encoder_k.transformer.blocks.layers.6.linear1.bias', 'encoder_k.transformer.blocks.layers.6.linear2.weight', 'encoder_k.transformer.blocks.layers.6.linear2.bias', 'encoder_k.transformer.blocks.layers.6.norm1.weight', 'encoder_k.transformer.blocks.layers.6.norm1.bias', 'encoder_k.transformer.blocks.layers.6.norm2.weight', 'encoder_k.transformer.blocks.layers.6.norm2.bias', 'encoder_k.transformer.blocks.layers.7.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.7.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.7.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.7.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.7.linear1.weight', 'encoder_k.transformer.blocks.layers.7.linear1.bias', 'encoder_k.transformer.blocks.layers.7.linear2.weight', 'encoder_k.transformer.blocks.layers.7.linear2.bias', 'encoder_k.transformer.blocks.layers.7.norm1.weight', 'encoder_k.transformer.blocks.layers.7.norm1.bias', 'encoder_k.transformer.blocks.layers.7.norm2.weight', 'encoder_k.transformer.blocks.layers.7.norm2.bias', 'encoder_k.transformer.blocks.layers.8.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.8.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.8.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.8.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.8.linear1.weight', 'encoder_k.transformer.blocks.layers.8.linear1.bias', 'encoder_k.transformer.blocks.layers.8.linear2.weight', 'encoder_k.transformer.blocks.layers.8.linear2.bias', 'encoder_k.transformer.blocks.layers.8.norm1.weight', 'encoder_k.transformer.blocks.layers.8.norm1.bias', 'encoder_k.transformer.blocks.layers.8.norm2.weight', 'encoder_k.transformer.blocks.layers.8.norm2.bias', 'encoder_k.transformer.blocks.layers.9.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.9.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.9.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.9.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.9.linear1.weight', 'encoder_k.transformer.blocks.layers.9.linear1.bias', 'encoder_k.transformer.blocks.layers.9.linear2.weight', 'encoder_k.transformer.blocks.layers.9.linear2.bias', 'encoder_k.transformer.blocks.layers.9.norm1.weight', 'encoder_k.transformer.blocks.layers.9.norm1.bias', 'encoder_k.transformer.blocks.layers.9.norm2.weight', 'encoder_k.transformer.blocks.layers.9.norm2.bias', 'encoder_k.transformer.blocks.layers.10.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.10.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.10.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.10.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.10.linear1.weight', 'encoder_k.transformer.blocks.layers.10.linear1.bias', 'encoder_k.transformer.blocks.layers.10.linear2.weight', 'encoder_k.transformer.blocks.layers.10.linear2.bias', 'encoder_k.transformer.blocks.layers.10.norm1.weight', 'encoder_k.transformer.blocks.layers.10.norm1.bias', 'encoder_k.transformer.blocks.layers.10.norm2.weight', 'encoder_k.transformer.blocks.layers.10.norm2.bias', 'encoder_k.transformer.blocks.layers.11.self_attn.in_proj_weight', 'encoder_k.transformer.blocks.layers.11.self_attn.in_proj_bias', 'encoder_k.transformer.blocks.layers.11.self_attn.out_proj.weight', 'encoder_k.transformer.blocks.layers.11.self_attn.out_proj.bias', 'encoder_k.transformer.blocks.layers.11.linear1.weight', 'encoder_k.transformer.blocks.layers.11.linear1.bias', 'encoder_k.transformer.blocks.layers.11.linear2.weight', 'encoder_k.transformer.blocks.layers.11.linear2.bias', 'encoder_k.transformer.blocks.layers.11.norm1.weight', 'encoder_k.transformer.blocks.layers.11.norm1.bias', 'encoder_k.transformer.blocks.layers.11.norm2.weight', 'encoder_k.transformer.blocks.layers.11.norm2.bias', 'encoder_k_proj.0.weight', 'encoder_k_proj.0.bias', 'encoder_k_proj.2.weight', 'encoder_k_proj.2.bias'])
[2025-12-02 02:37:37] Starting linear evaluation for 10 epochs...
[2025-12-02 02:43:43] Epoch 1/10, Avg. Running Loss: 11.048948', Train Acc:67.30% Test Acc: 82.23%
[2025-12-02 02:49:52] Epoch 2/10, Avg. Running Loss: 16.111451', Train Acc:67.30% Test Acc: 82.23%
[2025-12-02 02:56:02] Epoch 3/10, Avg. Running Loss: 9.056740', Train Acc:67.29% Test Acc: 82.23%
[2025-12-02 03:02:11] Epoch 4/10, Avg. Running Loss: 10.381304', Train Acc:67.30% Test Acc: 82.23%
[2025-12-02 03:08:21] Epoch 5/10, Avg. Running Loss: 9.082876', Train Acc:32.70% Test Acc: 17.77%
[2025-12-02 03:14:30] Epoch 6/10, Avg. Running Loss: 8.693940', Train Acc:67.30% Test Acc: 82.23%
[2025-12-02 03:20:39] Epoch 7/10, Avg. Running Loss: 8.561777', Train Acc:39.45% Test Acc: 21.59%
[2025-12-02 03:26:49] Epoch 8/10, Avg. Running Loss: 9.378690', Train Acc:32.70% Test Acc: 17.77%
[2025-12-02 03:32:58] Epoch 9/10, Avg. Running Loss: 12.788266', Train Acc:67.30% Test Acc: 82.23%
[2025-12-02 03:39:07] Epoch 10/10, Avg. Running Loss: 6.691679', Train Acc:67.30% Test Acc: 82.23%
[2025-12-02 03:39:42] Classification Report:
              precision    recall  f1-score   support

           0       0.82      1.00      0.90      2800
           1       0.00      0.00      0.00       605

    accuracy                           0.82      3405
   macro avg       0.41      0.50      0.45      3405
weighted avg       0.68      0.82      0.74      3405

[2025-12-02 03:39:42] Confusion Matrix:
[[2800    0]
 [ 605    0]]
[2025-12-02 03:39:42] Saved confusion matrix to /content/drive/MyDrive/Colab Notebooks/7_Py_DL/FP/artifacts/confusion_matrix_20251202_033907.png
[2025-12-02 03:39:42] MoCo backbone testing complete!
[2025-12-02 03:39:42] MoCo backbone testing complete!!
[2025-12-02 03:39:43] Saved testing stats to /content/drive/MyDrive/Colab Notebooks/7_Py_DL/FP/artifacts//test_stats.json
